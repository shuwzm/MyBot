2020-05-09 00:00:31 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:00:31 [root] WARNING: The price is $299.99
2020-05-09 00:00:31 [root] WARNING: status: Sold Out
2020-05-09 00:00:33 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:00:33 [root] WARNING: The price is $299.99
2020-05-09 00:00:33 [root] WARNING: status: Sold Out
2020-05-09 00:00:37 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:00:37 [root] WARNING: The price is $249.99
2020-05-09 00:00:37 [root] WARNING: status: Add to Cart
2020-05-09 00:00:56 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:00:56 [root] WARNING: The price is $299.99
2020-05-09 00:00:56 [root] WARNING: status: Sold Out
2020-05-09 00:00:59 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:00:59 [root] WARNING: The price is $299.99
2020-05-09 00:00:59 [root] WARNING: status: Sold Out
2020-05-09 00:01:02 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:01:02 [root] WARNING: The price is $249.99
2020-05-09 00:01:02 [root] WARNING: status: Add to Cart
2020-05-09 00:01:23 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:01:23 [root] WARNING: The price is $299.99
2020-05-09 00:01:23 [root] WARNING: status: Sold Out
2020-05-09 00:01:26 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:01:26 [root] WARNING: The price is $299.99
2020-05-09 00:01:26 [root] WARNING: status: Sold Out
2020-05-09 00:01:29 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:01:29 [root] WARNING: The price is $249.99
2020-05-09 00:01:29 [root] WARNING: status: Add to Cart
2020-05-09 00:01:46 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:01:46 [root] WARNING: The price is $299.99
2020-05-09 00:01:46 [root] WARNING: status: Sold Out
2020-05-09 00:01:50 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:01:50 [root] WARNING: The price is $249.99
2020-05-09 00:01:50 [root] WARNING: status: Add to Cart
2020-05-09 00:01:52 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:01:52 [root] WARNING: The price is $299.99
2020-05-09 00:01:52 [root] WARNING: status: Sold Out
2020-05-09 00:02:11 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:02:11 [root] WARNING: The price is $249.99
2020-05-09 00:02:11 [root] WARNING: status: Add to Cart
2020-05-09 00:02:14 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:02:14 [root] WARNING: The price is $299.99
2020-05-09 00:02:14 [root] WARNING: status: Sold Out
2020-05-09 00:02:17 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:02:17 [root] WARNING: The price is $299.99
2020-05-09 00:02:17 [root] WARNING: status: Sold Out
2020-05-09 00:02:42 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:02:42 [root] WARNING: The price is $299.99
2020-05-09 00:02:42 [root] WARNING: status: Sold Out
2020-05-09 00:02:48 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:02:48 [root] WARNING: The price is $249.99
2020-05-09 00:02:48 [root] WARNING: status: Add to Cart
2020-05-09 00:02:50 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:02:50 [root] WARNING: The price is $299.99
2020-05-09 00:02:50 [root] WARNING: status: Sold Out
2020-05-09 00:03:08 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:03:08 [root] WARNING: The price is $299.99
2020-05-09 00:03:08 [root] WARNING: status: Sold Out
2020-05-09 00:03:11 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:03:11 [root] WARNING: The price is $299.99
2020-05-09 00:03:11 [root] WARNING: status: Sold Out
2020-05-09 00:03:14 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:03:14 [root] WARNING: The price is $249.99
2020-05-09 00:03:14 [root] WARNING: status: Add to Cart
2020-05-09 00:03:31 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:03:31 [root] WARNING: The price is $299.99
2020-05-09 00:03:31 [root] WARNING: status: Sold Out
2020-05-09 00:03:33 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:03:33 [root] WARNING: The price is $299.99
2020-05-09 00:03:33 [root] WARNING: status: Sold Out
2020-05-09 00:03:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-space-gray/5985609.p?skuId=5985609> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 30, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:03:55 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:03:55 [root] WARNING: The price is $299.99
2020-05-09 00:03:55 [root] WARNING: status: Sold Out
2020-05-09 00:03:58 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:03:58 [root] WARNING: The price is $299.99
2020-05-09 00:03:58 [root] WARNING: status: Sold Out
2020-05-09 00:04:02 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:04:02 [root] WARNING: The price is $249.99
2020-05-09 00:04:02 [root] WARNING: status: Add to Cart
2020-05-09 00:04:24 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:04:24 [root] WARNING: The price is $249.99
2020-05-09 00:04:24 [root] WARNING: status: Add to Cart
2020-05-09 00:04:27 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:04:27 [root] WARNING: The price is $299.99
2020-05-09 00:04:27 [root] WARNING: status: Sold Out
2020-05-09 00:04:29 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:04:29 [root] WARNING: The price is $299.99
2020-05-09 00:04:29 [root] WARNING: status: Sold Out
2020-05-09 00:04:47 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:04:47 [root] WARNING: The price is $299.99
2020-05-09 00:04:47 [root] WARNING: status: Sold Out
2020-05-09 00:04:50 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:04:50 [root] WARNING: The price is $299.99
2020-05-09 00:04:50 [root] WARNING: status: Sold Out
2020-05-09 00:04:54 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:04:54 [root] WARNING: The price is $249.99
2020-05-09 00:04:54 [root] WARNING: status: Add to Cart
2020-05-09 00:05:13 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:05:13 [root] WARNING: The price is $249.99
2020-05-09 00:05:13 [root] WARNING: status: Add to Cart
2020-05-09 00:05:16 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:05:16 [root] WARNING: The price is $299.99
2020-05-09 00:05:16 [root] WARNING: status: Sold Out
2020-05-09 00:05:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 30, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:05:37 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:05:37 [root] WARNING: The price is $299.99
2020-05-09 00:05:37 [root] WARNING: status: Sold Out
2020-05-09 00:05:41 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:05:41 [root] WARNING: The price is $299.99
2020-05-09 00:05:41 [root] WARNING: status: Sold Out
2020-05-09 00:05:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-space-gray/5985609.p?skuId=5985609> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 30, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:06:02 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:06:02 [root] WARNING: The price is $299.99
2020-05-09 00:06:02 [root] WARNING: status: Sold Out
2020-05-09 00:06:07 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Space Gray
2020-05-09 00:06:07 [root] WARNING: The price is $249.99
2020-05-09 00:06:07 [root] WARNING: status: Add to Cart
2020-05-09 00:06:09 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:06:09 [root] WARNING: The price is $299.99
2020-05-09 00:06:09 [root] WARNING: status: Sold Out
2020-05-09 00:09:44 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:09:44 [root] WARNING: The price is $299.99
2020-05-09 00:09:44 [root] WARNING: status: Sold Out
2020-05-09 00:09:46 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:09:46 [root] WARNING: The price is $399.99
2020-05-09 00:09:46 [root] WARNING: status: Sold Out
2020-05-09 00:09:49 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:09:49 [root] WARNING: The price is $199.99
2020-05-09 00:09:49 [root] WARNING: status: Add to Cart
2020-05-09 00:09:51 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:09:51 [root] WARNING: The price is $299.99
2020-05-09 00:09:51 [root] WARNING: status: Sold Out
2020-05-09 00:09:55 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:09:55 [root] WARNING: The price is $249.99
2020-05-09 00:09:55 [root] WARNING: status: Sold Out
2020-05-09 00:10:11 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:10:11 [root] WARNING: The price is $199.99
2020-05-09 00:10:11 [root] WARNING: status: Sold Out
2020-05-09 00:10:14 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:10:14 [root] WARNING: The price is $399.99
2020-05-09 00:10:14 [root] WARNING: status: Sold Out
2020-05-09 00:10:16 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:10:16 [root] WARNING: The price is $299.99
2020-05-09 00:10:16 [root] WARNING: status: Sold Out
2020-05-09 00:10:19 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:10:19 [root] WARNING: The price is $249.99
2020-05-09 00:10:19 [root] WARNING: status: Sold Out
2020-05-09 00:10:21 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:10:21 [root] WARNING: The price is $299.99
2020-05-09 00:10:21 [root] WARNING: status: Sold Out
2020-05-09 00:10:38 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:10:38 [root] WARNING: The price is $399.99
2020-05-09 00:10:38 [root] WARNING: status: Sold Out
2020-05-09 00:10:41 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:10:41 [root] WARNING: The price is $299.99
2020-05-09 00:10:41 [root] WARNING: status: Sold Out
2020-05-09 00:10:44 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:10:44 [root] WARNING: The price is $199.99
2020-05-09 00:10:44 [root] WARNING: status: Add to Cart
2020-05-09 00:10:46 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:10:46 [root] WARNING: The price is $299.99
2020-05-09 00:10:46 [root] WARNING: status: Sold Out
2020-05-09 00:10:51 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:10:51 [root] WARNING: The price is $249.99
2020-05-09 00:10:51 [root] WARNING: status: Sold Out
2020-05-09 00:11:08 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:11:08 [root] WARNING: The price is $299.99
2020-05-09 00:11:08 [root] WARNING: status: Sold Out
2020-05-09 00:11:11 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:11:11 [root] WARNING: The price is $299.99
2020-05-09 00:11:11 [root] WARNING: status: Sold Out
2020-05-09 00:11:14 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:11:14 [root] WARNING: The price is $249.99
2020-05-09 00:11:14 [root] WARNING: status: Sold Out
2020-05-09 00:11:16 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:11:16 [root] WARNING: The price is $399.99
2020-05-09 00:11:16 [root] WARNING: status: Sold Out
2020-05-09 00:11:18 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:11:18 [root] WARNING: The price is $199.99
2020-05-09 00:11:18 [root] WARNING: status: Add to Cart
2020-05-09 00:11:36 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:11:36 [root] WARNING: The price is $299.99
2020-05-09 00:11:36 [root] WARNING: status: Sold Out
2020-05-09 00:11:39 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:11:39 [root] WARNING: The price is $199.99
2020-05-09 00:11:39 [root] WARNING: status: Add to Cart
2020-05-09 00:11:42 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:11:42 [root] WARNING: The price is $399.99
2020-05-09 00:11:42 [root] WARNING: status: Sold Out
2020-05-09 00:11:44 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:11:44 [root] WARNING: The price is $299.99
2020-05-09 00:11:44 [root] WARNING: status: Sold Out
2020-05-09 00:11:48 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:11:48 [root] WARNING: The price is $249.99
2020-05-09 00:11:48 [root] WARNING: status: Sold Out
2020-05-09 00:12:05 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:12:05 [root] WARNING: The price is $399.99
2020-05-09 00:12:05 [root] WARNING: status: Sold Out
2020-05-09 00:12:08 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:12:08 [root] WARNING: The price is $199.99
2020-05-09 00:12:08 [root] WARNING: status: Add to Cart
2020-05-09 00:12:10 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:12:10 [root] WARNING: The price is $299.99
2020-05-09 00:12:10 [root] WARNING: status: Sold Out
2020-05-09 00:12:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:12:14 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001C18F65BAC8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/b419fca42bd34cf076ab1faa716d6f73/url
2020-05-09 00:12:16 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001C18E037988>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/b419fca42bd34cf076ab1faa716d6f73/url
2020-05-09 00:12:18 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001C18E03C2C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/b419fca42bd34cf076ab1faa716d6f73/url
2020-05-09 00:12:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001C18E03C388>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=57317): Max retries exceeded with url: /session/b419fca42bd34cf076ab1faa716d6f73/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001C18E03C388>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:12:39 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:12:39 [root] WARNING: The price is $399.99
2020-05-09 00:12:39 [root] WARNING: status: Sold Out
2020-05-09 00:12:41 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:12:41 [root] WARNING: The price is $299.99
2020-05-09 00:12:41 [root] WARNING: status: Sold Out
2020-05-09 00:12:44 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:12:44 [root] WARNING: The price is $249.99
2020-05-09 00:12:44 [root] WARNING: status: Sold Out
2020-05-09 00:12:47 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:12:47 [root] WARNING: The price is $199.99
2020-05-09 00:12:47 [root] WARNING: status: Add to Cart
2020-05-09 00:12:49 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:12:49 [root] WARNING: The price is $299.99
2020-05-09 00:12:49 [root] WARNING: status: Sold Out
2020-05-09 00:13:06 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:13:06 [root] WARNING: The price is $299.99
2020-05-09 00:13:06 [root] WARNING: status: Sold Out
2020-05-09 00:13:09 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:13:09 [root] WARNING: The price is $399.99
2020-05-09 00:13:09 [root] WARNING: status: Sold Out
2020-05-09 00:13:11 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:13:11 [root] WARNING: The price is $249.99
2020-05-09 00:13:11 [root] WARNING: status: Sold Out
2020-05-09 00:13:13 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:13:13 [root] WARNING: The price is $299.99
2020-05-09 00:13:13 [root] WARNING: status: Sold Out
2020-05-09 00:13:16 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:13:16 [root] WARNING: The price is $199.99
2020-05-09 00:13:16 [root] WARNING: status: Add to Cart
2020-05-09 00:13:33 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:13:33 [root] WARNING: The price is $299.99
2020-05-09 00:13:33 [root] WARNING: status: Sold Out
2020-05-09 00:13:36 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:13:36 [root] WARNING: The price is $299.99
2020-05-09 00:13:36 [root] WARNING: status: Sold Out
2020-05-09 00:13:38 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:13:38 [root] WARNING: The price is $399.99
2020-05-09 00:13:38 [root] WARNING: status: Sold Out
2020-05-09 00:13:41 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:13:41 [root] WARNING: The price is $249.99
2020-05-09 00:13:41 [root] WARNING: status: Sold Out
2020-05-09 00:13:44 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:13:44 [root] WARNING: The price is $199.99
2020-05-09 00:13:44 [root] WARNING: status: Add to Cart
2020-05-09 00:14:02 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:14:02 [root] WARNING: The price is $299.99
2020-05-09 00:14:02 [root] WARNING: status: Sold Out
2020-05-09 00:14:06 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:14:06 [root] WARNING: The price is $249.99
2020-05-09 00:14:06 [root] WARNING: status: Sold Out
2020-05-09 00:14:09 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:14:09 [root] WARNING: The price is $199.99
2020-05-09 00:14:09 [root] WARNING: status: Add to Cart
2020-05-09 00:14:11 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:14:11 [root] WARNING: The price is $299.99
2020-05-09 00:14:11 [root] WARNING: status: Sold Out
2020-05-09 00:14:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:14:33 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:14:33 [root] WARNING: The price is $199.99
2020-05-09 00:14:33 [root] WARNING: status: Add to Cart
2020-05-09 00:14:37 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:14:37 [root] WARNING: The price is $299.99
2020-05-09 00:14:37 [root] WARNING: status: Sold Out
2020-05-09 00:14:39 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:14:39 [root] WARNING: The price is $299.99
2020-05-09 00:14:39 [root] WARNING: status: Sold Out
2020-05-09 00:14:42 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:14:42 [root] WARNING: The price is $249.99
2020-05-09 00:14:42 [root] WARNING: status: Sold Out
2020-05-09 00:14:45 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:14:45 [root] WARNING: The price is $399.99
2020-05-09 00:14:45 [root] WARNING: status: Sold Out
2020-05-09 00:15:05 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:15:05 [root] WARNING: The price is $299.99
2020-05-09 00:15:05 [root] WARNING: status: Sold Out
2020-05-09 00:15:08 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:15:08 [root] WARNING: The price is $199.99
2020-05-09 00:15:08 [root] WARNING: status: Add to Cart
2020-05-09 00:15:10 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:15:10 [root] WARNING: The price is $299.99
2020-05-09 00:15:10 [root] WARNING: status: Sold Out
2020-05-09 00:15:12 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:15:12 [root] WARNING: The price is $399.99
2020-05-09 00:15:12 [root] WARNING: status: Sold Out
2020-05-09 00:15:14 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:15:14 [root] WARNING: The price is $249.99
2020-05-09 00:15:14 [root] WARNING: status: Sold Out
2020-05-09 00:15:32 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:15:32 [root] WARNING: The price is $299.99
2020-05-09 00:15:32 [root] WARNING: status: Sold Out
2020-05-09 00:15:35 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:15:35 [root] WARNING: The price is $299.99
2020-05-09 00:15:35 [root] WARNING: status: Sold Out
2020-05-09 00:15:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:15:39 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8ACA6D88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fb262de31f05f6552d22c554cca2225b/url
2020-05-09 00:15:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8C24DD88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fb262de31f05f6552d22c554cca2225b/url
2020-05-09 00:15:43 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8C2566C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fb262de31f05f6552d22c554cca2225b/url
2020-05-09 00:15:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000013A8C256788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=58147): Max retries exceeded with url: /session/fb262de31f05f6552d22c554cca2225b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8C256788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:15:47 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8AB07208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fb262de31f05f6552d22c554cca2225b/url
2020-05-09 00:15:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8C2576C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fb262de31f05f6552d22c554cca2225b/url
2020-05-09 00:15:51 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8C25DD08>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fb262de31f05f6552d22c554cca2225b/url
2020-05-09 00:15:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000013A8C269548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=58147): Max retries exceeded with url: /session/fb262de31f05f6552d22c554cca2225b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013A8C269548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:16:15 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:16:15 [root] WARNING: The price is $299.99
2020-05-09 00:16:15 [root] WARNING: status: Sold Out
2020-05-09 00:16:18 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:16:18 [root] WARNING: The price is $199.99
2020-05-09 00:16:18 [root] WARNING: status: Add to Cart
2020-05-09 00:16:21 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:16:21 [root] WARNING: The price is $399.99
2020-05-09 00:16:21 [root] WARNING: status: Sold Out
2020-05-09 00:16:24 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:16:24 [root] WARNING: The price is $249.99
2020-05-09 00:16:24 [root] WARNING: status: Sold Out
2020-05-09 00:16:26 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:16:26 [root] WARNING: The price is $299.99
2020-05-09 00:16:26 [root] WARNING: status: Sold Out
2020-05-09 00:16:45 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:16:45 [root] WARNING: The price is $399.99
2020-05-09 00:16:45 [root] WARNING: status: Sold Out
2020-05-09 00:16:49 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:16:49 [root] WARNING: The price is $249.99
2020-05-09 00:16:49 [root] WARNING: status: Sold Out
2020-05-09 00:16:52 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:16:52 [root] WARNING: The price is $199.99
2020-05-09 00:16:52 [root] WARNING: status: Add to Cart
2020-05-09 00:16:54 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:16:54 [root] WARNING: The price is $299.99
2020-05-09 00:16:54 [root] WARNING: status: Sold Out
2020-05-09 00:16:56 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:16:56 [root] WARNING: The price is $299.99
2020-05-09 00:16:56 [root] WARNING: status: Sold Out
2020-05-09 00:17:13 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:17:13 [root] WARNING: The price is $399.99
2020-05-09 00:17:13 [root] WARNING: status: Sold Out
2020-05-09 00:17:16 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:17:16 [root] WARNING: The price is $199.99
2020-05-09 00:17:16 [root] WARNING: status: Add to Cart
2020-05-09 00:17:19 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:17:19 [root] WARNING: The price is $249.99
2020-05-09 00:17:19 [root] WARNING: status: Sold Out
2020-05-09 00:17:24 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:17:24 [root] WARNING: The price is $299.99
2020-05-09 00:17:24 [root] WARNING: status: Sold Out
2020-05-09 00:17:26 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:17:26 [root] WARNING: The price is $299.99
2020-05-09 00:17:26 [root] WARNING: status: Sold Out
2020-05-09 00:17:44 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:17:44 [root] WARNING: The price is $199.99
2020-05-09 00:17:44 [root] WARNING: status: Add to Cart
2020-05-09 00:17:47 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:17:47 [root] WARNING: The price is $299.99
2020-05-09 00:17:47 [root] WARNING: status: Sold Out
2020-05-09 00:17:52 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:17:52 [root] WARNING: The price is $249.99
2020-05-09 00:17:52 [root] WARNING: status: Sold Out
2020-05-09 00:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:17:55 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020679DCB088>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/3a5b991b907476283f7614aa81e0bf11/url
2020-05-09 00:17:57 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020679DF31C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/3a5b991b907476283f7614aa81e0bf11/url
2020-05-09 00:17:59 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020679DF36C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/3a5b991b907476283f7614aa81e0bf11/url
2020-05-09 00:18:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002067B256088>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=58682): Max retries exceeded with url: /session/3a5b991b907476283f7614aa81e0bf11/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002067B256088>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:19:12 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:19:12 [root] WARNING: The price is $299.99
2020-05-09 00:19:12 [root] WARNING: status: Sold Out
2020-05-09 00:19:16 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:19:16 [root] WARNING: The price is $199.99
2020-05-09 00:19:16 [root] WARNING: status: Add to Cart
2020-05-09 00:19:19 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:19:19 [root] WARNING: The price is $249.99
2020-05-09 00:19:19 [root] WARNING: status: Sold Out
2020-05-09 00:19:21 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:19:21 [root] WARNING: The price is $299.99
2020-05-09 00:19:21 [root] WARNING: status: Sold Out
2020-05-09 00:19:23 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:19:23 [root] WARNING: The price is $399.99
2020-05-09 00:19:23 [root] WARNING: status: Sold Out
2020-05-09 00:19:48 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:19:48 [root] WARNING: The price is $399.99
2020-05-09 00:19:48 [root] WARNING: status: Sold Out
2020-05-09 00:19:50 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:19:50 [root] WARNING: The price is $299.99
2020-05-09 00:19:50 [root] WARNING: status: Sold Out
2020-05-09 00:19:52 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:19:52 [root] WARNING: The price is $299.99
2020-05-09 00:19:52 [root] WARNING: status: Sold Out
2020-05-09 00:19:54 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:19:54 [root] WARNING: The price is $199.99
2020-05-09 00:19:54 [root] WARNING: status: Add to Cart
2020-05-09 00:19:57 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:19:57 [root] WARNING: The price is $249.99
2020-05-09 00:19:57 [root] WARNING: status: Sold Out
2020-05-09 00:20:24 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:20:24 [root] WARNING: The price is $299.99
2020-05-09 00:20:24 [root] WARNING: status: Sold Out
2020-05-09 00:20:29 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:20:29 [root] WARNING: The price is $249.99
2020-05-09 00:20:29 [root] WARNING: status: Sold Out
2020-05-09 00:20:31 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:20:31 [root] WARNING: The price is $299.99
2020-05-09 00:20:31 [root] WARNING: status: Sold Out
2020-05-09 00:20:33 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:20:33 [root] WARNING: The price is $399.99
2020-05-09 00:20:33 [root] WARNING: status: Sold Out
2020-05-09 00:20:35 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:20:35 [root] WARNING: The price is $199.99
2020-05-09 00:20:35 [root] WARNING: status: Add to Cart
2020-05-09 00:21:02 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:21:02 [root] WARNING: The price is $299.99
2020-05-09 00:21:02 [root] WARNING: status: Sold Out
2020-05-09 00:21:04 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:21:04 [root] WARNING: The price is $199.99
2020-05-09 00:21:04 [root] WARNING: status: Add to Cart
2020-05-09 00:21:07 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:21:07 [root] WARNING: The price is $299.99
2020-05-09 00:21:07 [root] WARNING: status: Sold Out
2020-05-09 00:21:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:21:10 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029C8788A988>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/7b6cc5f09cad43cb63605b6b0a4220fd/url
2020-05-09 00:21:12 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029C86267848>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/7b6cc5f09cad43cb63605b6b0a4220fd/url
2020-05-09 00:21:14 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029C8626C148>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/7b6cc5f09cad43cb63605b6b0a4220fd/url
2020-05-09 00:21:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029C8626C208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=59219): Max retries exceeded with url: /session/7b6cc5f09cad43cb63605b6b0a4220fd/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029C8626C208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:21:44 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:21:44 [root] WARNING: The price is $399.99
2020-05-09 00:21:44 [root] WARNING: status: Sold Out
2020-05-09 00:21:48 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:21:48 [root] WARNING: The price is $249.99
2020-05-09 00:21:48 [root] WARNING: status: Sold Out
2020-05-09 00:21:51 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:21:51 [root] WARNING: The price is $199.99
2020-05-09 00:21:51 [root] WARNING: status: Add to Cart
2020-05-09 00:21:54 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:21:54 [root] WARNING: The price is $299.99
2020-05-09 00:21:54 [root] WARNING: status: Sold Out
2020-05-09 00:21:56 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:21:56 [root] WARNING: The price is $299.99
2020-05-09 00:21:56 [root] WARNING: status: Sold Out
2020-05-09 00:22:22 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:22:22 [root] WARNING: The price is $399.99
2020-05-09 00:22:22 [root] WARNING: status: Sold Out
2020-05-09 00:22:26 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:22:26 [root] WARNING: The price is $249.99
2020-05-09 00:22:26 [root] WARNING: status: Sold Out
2020-05-09 00:22:29 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:22:29 [root] WARNING: The price is $299.99
2020-05-09 00:22:29 [root] WARNING: status: Sold Out
2020-05-09 00:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:22:34 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002485F3AB108>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/b22b91999977ca310d186ea4b624f246/url
2020-05-09 00:22:36 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002485F3D3DC8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/b22b91999977ca310d186ea4b624f246/url
2020-05-09 00:22:38 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000248608516C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/b22b91999977ca310d186ea4b624f246/url
2020-05-09 00:22:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000024860851788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=59466): Max retries exceeded with url: /session/b22b91999977ca310d186ea4b624f246/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024860851788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:23:08 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:23:08 [root] WARNING: The price is $299.99
2020-05-09 00:23:08 [root] WARNING: status: Sold Out
2020-05-09 00:23:10 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:23:10 [root] WARNING: The price is $399.99
2020-05-09 00:23:10 [root] WARNING: status: Sold Out
2020-05-09 00:23:14 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:23:14 [root] WARNING: The price is $249.99
2020-05-09 00:23:14 [root] WARNING: status: Sold Out
2020-05-09 00:23:16 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:23:16 [root] WARNING: The price is $199.99
2020-05-09 00:23:16 [root] WARNING: status: Add to Cart
2020-05-09 00:23:18 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:23:18 [root] WARNING: The price is $299.99
2020-05-09 00:23:18 [root] WARNING: status: Sold Out
2020-05-09 00:23:44 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:23:44 [root] WARNING: The price is $299.99
2020-05-09 00:23:44 [root] WARNING: status: Sold Out
2020-05-09 00:23:47 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:23:47 [root] WARNING: The price is $249.99
2020-05-09 00:23:47 [root] WARNING: status: Sold Out
2020-05-09 00:23:50 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:23:50 [root] WARNING: The price is $299.99
2020-05-09 00:23:50 [root] WARNING: status: Sold Out
2020-05-09 00:23:52 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:23:52 [root] WARNING: The price is $399.99
2020-05-09 00:23:52 [root] WARNING: status: Sold Out
2020-05-09 00:23:54 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:23:54 [root] WARNING: The price is $199.99
2020-05-09 00:23:54 [root] WARNING: status: Add to Cart
2020-05-09 00:24:24 [root] WARNING: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:24:24 [root] WARNING: The price is $399.99
2020-05-09 00:24:24 [root] WARNING: status: Sold Out
2020-05-09 00:24:28 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:24:28 [root] WARNING: The price is $299.99
2020-05-09 00:24:28 [root] WARNING: status: Sold Out
2020-05-09 00:24:31 [root] WARNING: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:24:31 [root] WARNING: The price is $249.99
2020-05-09 00:24:31 [root] WARNING: status: Sold Out
2020-05-09 00:24:35 [root] WARNING: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:24:35 [root] WARNING: The price is $199.99
2020-05-09 00:24:35 [root] WARNING: status: Add to Cart
2020-05-09 00:24:37 [root] WARNING: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:24:37 [root] WARNING: The price is $299.99
2020-05-09 00:24:37 [root] WARNING: status: Sold Out
2020-05-09 00:25:27 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:25:27 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:25:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:25:27 [scrapy.extensions.telnet] INFO: Telnet Password: 75a32fb5f0bc9932
2020-05-09 00:25:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:25:33 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2020-05-09 00:25:35 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2020-05-09 00:25:49 [twisted] CRITICAL: Unhandled error in Deferred:
2020-05-09 00:25:49 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\scrapy\crawler.py", line 88, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\scrapy\crawler.py", line 100, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\scrapy\spiders\__init__.py", line 49, in from_crawler
    spider = cls(*args, **kwargs)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 22, in __init__
    self.driver = webdriver.Chrome('c:\\webdriver\chromedriver.exe')
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\chrome\webdriver.py", line 81, in __init__
    desired_capabilities=desired_capabilities)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 157, in __init__
    self.start_session(capabilities, browser_profile)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 252, in start_session
    response = self.execute(Command.NEW_SESSION, parameters)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:26:21 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:26:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:26:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:26:21 [scrapy.extensions.telnet] INFO: Telnet Password: 04e8446a0ed08603
2020-05-09 00:26:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:26:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:26:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:26:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:26:27 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:26:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:26:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:26:38 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:26:38 [root] INFO: The price is $299.99
2020-05-09 00:26:38 [root] INFO: status: Sold Out
2020-05-09 00:26:42 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:26:42 [root] INFO: The price is $199.99
2020-05-09 00:26:42 [root] INFO: status: Add to Cart
2020-05-09 00:26:44 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:26:44 [root] INFO: The price is $299.99
2020-05-09 00:26:44 [root] INFO: status: Sold Out
2020-05-09 00:26:46 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:26:46 [root] INFO: The price is $399.99
2020-05-09 00:26:46 [root] INFO: status: Sold Out
2020-05-09 00:26:49 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:26:49 [root] INFO: The price is $249.99
2020-05-09 00:26:49 [root] INFO: status: Sold Out
2020-05-09 00:26:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:26:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573447,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.857469,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 26, 49, 473882),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 26, 27, 616413)}
2020-05-09 00:26:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:27:12 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:27:12 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:27:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:27:12 [scrapy.extensions.telnet] INFO: Telnet Password: d9f437d131dc6bab
2020-05-09 00:27:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:27:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:27:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:27:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:27:18 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:27:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:27:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:27:24 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:27:24 [root] INFO: The price is $199.99
2020-05-09 00:27:24 [root] INFO: status: Add to Cart
2020-05-09 00:27:28 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:27:28 [root] INFO: The price is $249.99
2020-05-09 00:27:28 [root] INFO: status: Sold Out
2020-05-09 00:27:30 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:27:30 [root] INFO: The price is $399.99
2020-05-09 00:27:30 [root] INFO: status: Sold Out
2020-05-09 00:27:32 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:27:32 [root] INFO: The price is $299.99
2020-05-09 00:27:32 [root] INFO: status: Sold Out
2020-05-09 00:27:34 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:27:34 [root] INFO: The price is $299.99
2020-05-09 00:27:34 [root] INFO: status: Sold Out
2020-05-09 00:27:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:27:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573437,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.453742,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 27, 34, 928500),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 27, 18, 474758)}
2020-05-09 00:27:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:27:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:27:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:27:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:27:58 [scrapy.extensions.telnet] INFO: Telnet Password: 581e07fa18e8e7c7
2020-05-09 00:27:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:28:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:28:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:28:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:28:03 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:28:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:28:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:28:10 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:28:10 [root] INFO: The price is $299.99
2020-05-09 00:28:10 [root] INFO: status: Sold Out
2020-05-09 00:28:14 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:28:14 [root] INFO: The price is $199.99
2020-05-09 00:28:14 [root] INFO: status: Add to Cart
2020-05-09 00:28:17 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:28:17 [root] INFO: The price is $399.99
2020-05-09 00:28:17 [root] INFO: status: Sold Out
2020-05-09 00:28:20 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:28:20 [root] INFO: The price is $249.99
2020-05-09 00:28:20 [root] INFO: status: Sold Out
2020-05-09 00:28:23 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:28:23 [root] INFO: The price is $299.99
2020-05-09 00:28:23 [root] INFO: status: Sold Out
2020-05-09 00:28:23 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:28:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 572967,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.227101,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 28, 23, 133692),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 28, 3, 906591)}
2020-05-09 00:28:23 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:28:46 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:28:46 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:28:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:28:46 [scrapy.extensions.telnet] INFO: Telnet Password: e92f565bad55bb81
2020-05-09 00:28:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:28:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:28:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:28:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:28:52 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:28:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:28:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:29:01 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:29:01 [root] INFO: The price is $299.99
2020-05-09 00:29:01 [root] INFO: status: Sold Out
2020-05-09 00:29:03 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:29:03 [root] INFO: The price is $299.99
2020-05-09 00:29:03 [root] INFO: status: Sold Out
2020-05-09 00:29:06 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:29:06 [root] INFO: The price is $399.99
2020-05-09 00:29:06 [root] INFO: status: Sold Out
2020-05-09 00:29:10 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:29:10 [root] INFO: The price is $249.99
2020-05-09 00:29:10 [root] INFO: status: Sold Out
2020-05-09 00:29:12 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:29:12 [root] INFO: The price is $199.99
2020-05-09 00:29:12 [root] INFO: status: Add to Cart
2020-05-09 00:29:12 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:29:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 572973,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.712236,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 29, 12, 957002),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 28, 52, 244766)}
2020-05-09 00:29:12 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:29:36 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:29:36 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:29:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:29:36 [scrapy.extensions.telnet] INFO: Telnet Password: 7b871a6de242908d
2020-05-09 00:29:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:29:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:29:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:29:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:29:42 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:29:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:29:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:29:51 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:29:51 [root] INFO: The price is $299.99
2020-05-09 00:29:51 [root] INFO: status: Sold Out
2020-05-09 00:29:56 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:29:56 [root] INFO: The price is $399.99
2020-05-09 00:29:56 [root] INFO: status: Sold Out
2020-05-09 00:29:59 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:29:59 [root] INFO: The price is $199.99
2020-05-09 00:29:59 [root] INFO: status: Add to Cart
2020-05-09 00:30:03 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:30:03 [root] INFO: The price is $249.99
2020-05-09 00:30:03 [root] INFO: status: Sold Out
2020-05-09 00:30:05 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:30:05 [root] INFO: The price is $299.99
2020-05-09 00:30:05 [root] INFO: status: Sold Out
2020-05-09 00:30:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:30:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573019,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 23.904022,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 30, 5, 987652),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 29, 42, 83630)}
2020-05-09 00:30:05 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:30:29 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:30:29 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:30:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:30:29 [scrapy.extensions.telnet] INFO: Telnet Password: 3a96e8254f31dff4
2020-05-09 00:30:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:30:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:30:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:30:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:30:35 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:30:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:30:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:30:46 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:30:46 [root] INFO: The price is $299.99
2020-05-09 00:30:46 [root] INFO: status: Sold Out
2020-05-09 00:30:49 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:30:49 [root] INFO: The price is $199.99
2020-05-09 00:30:49 [root] INFO: status: Add to Cart
2020-05-09 00:30:52 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:30:52 [root] INFO: The price is $249.99
2020-05-09 00:30:52 [root] INFO: status: Sold Out
2020-05-09 00:30:55 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:30:55 [root] INFO: The price is $299.99
2020-05-09 00:30:55 [root] INFO: status: Sold Out
2020-05-09 00:30:57 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:30:57 [root] INFO: The price is $399.99
2020-05-09 00:30:57 [root] INFO: status: Sold Out
2020-05-09 00:30:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:30:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573000,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.301184,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 30, 57, 383062),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 30, 35, 81878)}
2020-05-09 00:30:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:31:20 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:31:20 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:31:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:31:20 [scrapy.extensions.telnet] INFO: Telnet Password: 515eee7d816586b3
2020-05-09 00:31:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:31:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:31:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:31:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:31:26 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:31:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:31:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:31:31 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:31:31 [root] INFO: The price is $399.99
2020-05-09 00:31:31 [root] INFO: status: Sold Out
2020-05-09 00:31:34 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:31:34 [root] INFO: The price is $299.99
2020-05-09 00:31:34 [root] INFO: status: Sold Out
2020-05-09 00:31:37 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:31:37 [root] INFO: The price is $249.99
2020-05-09 00:31:37 [root] INFO: status: Sold Out
2020-05-09 00:31:40 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:31:40 [root] INFO: The price is $199.99
2020-05-09 00:31:40 [root] INFO: status: Add to Cart
2020-05-09 00:31:43 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:31:43 [root] INFO: The price is $299.99
2020-05-09 00:31:43 [root] INFO: status: Sold Out
2020-05-09 00:31:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:31:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573473,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.484864,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 31, 43, 24640),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 31, 26, 539776)}
2020-05-09 00:31:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:32:06 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:32:06 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:32:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:32:06 [scrapy.extensions.telnet] INFO: Telnet Password: ce0ce96160969a79
2020-05-09 00:32:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:32:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:32:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:32:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:32:12 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:32:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:32:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:32:19 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:32:19 [root] INFO: The price is $299.99
2020-05-09 00:32:19 [root] INFO: status: Sold Out
2020-05-09 00:32:22 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:32:22 [root] INFO: The price is $199.99
2020-05-09 00:32:22 [root] INFO: status: Add to Cart
2020-05-09 00:32:25 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:32:25 [root] INFO: The price is $299.99
2020-05-09 00:32:25 [root] INFO: status: Sold Out
2020-05-09 00:32:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:32:28 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D91549B6C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/cbc4723c40fea0b00bd6b6eb1cc06467/url
2020-05-09 00:32:30 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D913E66648>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/cbc4723c40fea0b00bd6b6eb1cc06467/url
2020-05-09 00:32:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D913E667C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/cbc4723c40fea0b00bd6b6eb1cc06467/url
2020-05-09 00:32:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D913E6D088>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=60946): Max retries exceeded with url: /session/cbc4723c40fea0b00bd6b6eb1cc06467/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D913E6D088>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:32:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:32:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573467,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.88367,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 32, 34, 993607),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 32, 12, 109937)}
2020-05-09 00:32:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:33:00 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:33:00 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:33:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:33:00 [scrapy.extensions.telnet] INFO: Telnet Password: 34f88dec6aa946ec
2020-05-09 00:33:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:33:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:33:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:33:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:33:06 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:33:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:33:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:33:12 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:33:12 [root] INFO: The price is $199.99
2020-05-09 00:33:12 [root] INFO: status: Add to Cart
2020-05-09 00:33:14 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:33:14 [root] INFO: The price is $399.99
2020-05-09 00:33:14 [root] INFO: status: Sold Out
2020-05-09 00:33:18 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:33:18 [root] INFO: The price is $249.99
2020-05-09 00:33:18 [root] INFO: status: Sold Out
2020-05-09 00:33:20 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:33:20 [root] INFO: The price is $299.99
2020-05-09 00:33:20 [root] INFO: status: Sold Out
2020-05-09 00:33:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:33:22 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:33:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573456,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.514207,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 33, 22, 634941),
 'log_count/ERROR': 1,
 'log_count/INFO': 22,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 33, 6, 120734)}
2020-05-09 00:33:22 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:33:47 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:33:47 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:33:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:33:47 [scrapy.extensions.telnet] INFO: Telnet Password: 29286d92991e7d6c
2020-05-09 00:33:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:33:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:33:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:33:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:33:53 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:33:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:33:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:33:59 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:33:59 [root] INFO: The price is $299.99
2020-05-09 00:33:59 [root] INFO: status: Sold Out
2020-05-09 00:34:02 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:34:02 [root] INFO: The price is $399.99
2020-05-09 00:34:02 [root] INFO: status: Sold Out
2020-05-09 00:34:05 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:34:05 [root] INFO: The price is $249.99
2020-05-09 00:34:05 [root] INFO: status: Sold Out
2020-05-09 00:34:08 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:34:08 [root] INFO: The price is $199.99
2020-05-09 00:34:08 [root] INFO: status: Add to Cart
2020-05-09 00:34:11 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:34:11 [root] INFO: The price is $299.99
2020-05-09 00:34:11 [root] INFO: status: Sold Out
2020-05-09 00:34:11 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:34:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573461,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.942844,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 34, 11, 735296),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 33, 53, 792452)}
2020-05-09 00:34:11 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:34:35 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:34:35 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:34:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:34:35 [scrapy.extensions.telnet] INFO: Telnet Password: d6abd97395dbe609
2020-05-09 00:34:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:34:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:34:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:34:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:34:40 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:34:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:34:46 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:34:46 [root] INFO: The price is $399.99
2020-05-09 00:34:46 [root] INFO: status: Sold Out
2020-05-09 00:34:50 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:34:50 [root] INFO: The price is $249.99
2020-05-09 00:34:50 [root] INFO: status: Sold Out
2020-05-09 00:34:52 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:34:52 [root] INFO: The price is $299.99
2020-05-09 00:34:52 [root] INFO: status: Sold Out
2020-05-09 00:34:54 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:34:54 [root] INFO: The price is $199.99
2020-05-09 00:34:54 [root] INFO: status: Add to Cart
2020-05-09 00:34:57 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:34:57 [root] INFO: The price is $299.99
2020-05-09 00:34:57 [root] INFO: status: Sold Out
2020-05-09 00:34:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:34:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573463,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.153313,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 34, 57, 109753),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 34, 40, 956440)}
2020-05-09 00:34:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:35:20 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:35:20 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:35:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:35:20 [scrapy.extensions.telnet] INFO: Telnet Password: 156db4752b118f88
2020-05-09 00:35:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:35:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:35:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:35:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:35:26 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:35:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:35:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:35:34 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:35:34 [root] INFO: The price is $299.99
2020-05-09 00:35:34 [root] INFO: status: Sold Out
2020-05-09 00:35:37 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:35:37 [root] INFO: The price is $299.99
2020-05-09 00:35:37 [root] INFO: status: Sold Out
2020-05-09 00:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:35:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC31F88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/2831c81e08c7dd150035219fad70e783/url
2020-05-09 00:35:43 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC45588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/2831c81e08c7dd150035219fad70e783/url
2020-05-09 00:35:45 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC45708>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/2831c81e08c7dd150035219fad70e783/url
2020-05-09 00:35:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002C3BAC486C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=61469): Max retries exceeded with url: /session/2831c81e08c7dd150035219fad70e783/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC486C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:35:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC48E48>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/2831c81e08c7dd150035219fad70e783/url
2020-05-09 00:35:51 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC4B048>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/2831c81e08c7dd150035219fad70e783/url
2020-05-09 00:35:53 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC59508>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/2831c81e08c7dd150035219fad70e783/url
2020-05-09 00:35:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002C3BAC595C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=61469): Max retries exceeded with url: /session/2831c81e08c7dd150035219fad70e783/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C3BAC595C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:35:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:35:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573456,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 29.317288,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 35, 55, 585819),
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'log_count/WARNING': 6,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 2,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 35, 26, 268531)}
2020-05-09 00:35:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:36:20 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:36:20 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:36:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:36:20 [scrapy.extensions.telnet] INFO: Telnet Password: 065f65c8e3619d99
2020-05-09 00:36:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:36:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:36:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:36:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:36:26 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:36:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:36:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:36:34 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:36:34 [root] INFO: The price is $249.99
2020-05-09 00:36:34 [root] INFO: status: Sold Out
2020-05-09 00:36:37 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:36:37 [root] INFO: The price is $399.99
2020-05-09 00:36:37 [root] INFO: status: Sold Out
2020-05-09 00:36:39 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:36:39 [root] INFO: The price is $299.99
2020-05-09 00:36:39 [root] INFO: status: Sold Out
2020-05-09 00:36:45 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:36:45 [root] INFO: The price is $299.99
2020-05-09 00:36:45 [root] INFO: status: Sold Out
2020-05-09 00:36:48 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:36:48 [root] INFO: The price is $199.99
2020-05-09 00:36:48 [root] INFO: status: Add to Cart
2020-05-09 00:36:48 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:36:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573426,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.114932,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 36, 48, 878847),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 36, 26, 763915)}
2020-05-09 00:36:48 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:37:12 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:37:12 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:37:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:37:12 [scrapy.extensions.telnet] INFO: Telnet Password: 924f47a3248fe201
2020-05-09 00:37:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:37:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:37:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:37:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:37:18 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:37:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:37:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:37:24 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:37:24 [root] INFO: The price is $299.99
2020-05-09 00:37:24 [root] INFO: status: Sold Out
2020-05-09 00:37:28 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:37:28 [root] INFO: The price is $249.99
2020-05-09 00:37:28 [root] INFO: status: Sold Out
2020-05-09 00:37:30 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:37:30 [root] INFO: The price is $299.99
2020-05-09 00:37:30 [root] INFO: status: Sold Out
2020-05-09 00:37:32 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:37:32 [root] INFO: The price is $399.99
2020-05-09 00:37:32 [root] INFO: status: Sold Out
2020-05-09 00:37:35 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:37:35 [root] INFO: The price is $199.99
2020-05-09 00:37:35 [root] INFO: status: Add to Cart
2020-05-09 00:37:35 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:37:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573447,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.925049,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 37, 35, 26328),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 37, 18, 101279)}
2020-05-09 00:37:35 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:37:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:37:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:37:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:37:58 [scrapy.extensions.telnet] INFO: Telnet Password: ee02362529c63d40
2020-05-09 00:37:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:38:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:38:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:38:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:38:04 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:38:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:38:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:38:11 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:38:11 [root] INFO: The price is $249.99
2020-05-09 00:38:11 [root] INFO: status: Sold Out
2020-05-09 00:38:14 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:38:14 [root] INFO: The price is $299.99
2020-05-09 00:38:14 [root] INFO: status: Sold Out
2020-05-09 00:38:16 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:38:16 [root] INFO: The price is $399.99
2020-05-09 00:38:16 [root] INFO: status: Sold Out
2020-05-09 00:38:19 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:38:19 [root] INFO: The price is $199.99
2020-05-09 00:38:19 [root] INFO: status: Add to Cart
2020-05-09 00:38:21 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:38:21 [root] INFO: The price is $299.99
2020-05-09 00:38:21 [root] INFO: status: Sold Out
2020-05-09 00:38:21 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:38:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573445,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.340054,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 38, 21, 584707),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 38, 4, 244653)}
2020-05-09 00:38:21 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:38:45 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:38:45 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:38:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:38:45 [scrapy.extensions.telnet] INFO: Telnet Password: 6d8aaf4f0f60b933
2020-05-09 00:38:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:38:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:38:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:38:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:38:51 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:38:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:38:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:38:57 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:38:57 [root] INFO: The price is $299.99
2020-05-09 00:38:57 [root] INFO: status: Sold Out
2020-05-09 00:39:00 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:39:00 [root] INFO: The price is $299.99
2020-05-09 00:39:00 [root] INFO: status: Sold Out
2020-05-09 00:39:03 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:39:03 [root] INFO: The price is $399.99
2020-05-09 00:39:03 [root] INFO: status: Sold Out
2020-05-09 00:39:06 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:39:06 [root] INFO: The price is $249.99
2020-05-09 00:39:06 [root] INFO: status: Sold Out
2020-05-09 00:39:09 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:39:09 [root] INFO: The price is $199.99
2020-05-09 00:39:09 [root] INFO: status: Add to Cart
2020-05-09 00:39:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:39:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573433,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 18.25112,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 39, 9, 352810),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 38, 51, 101690)}
2020-05-09 00:39:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:39:32 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:39:32 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:39:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:39:32 [scrapy.extensions.telnet] INFO: Telnet Password: a2c3f9aafc25801a
2020-05-09 00:39:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:39:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:39:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:39:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:39:38 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:39:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:39:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:39:43 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:39:43 [root] INFO: The price is $399.99
2020-05-09 00:39:43 [root] INFO: status: Sold Out
2020-05-09 00:39:46 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:39:46 [root] INFO: The price is $199.99
2020-05-09 00:39:46 [root] INFO: status: Sold Out
2020-05-09 00:39:49 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:39:49 [root] INFO: The price is $299.99
2020-05-09 00:39:49 [root] INFO: status: Sold Out
2020-05-09 00:39:51 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:39:51 [root] INFO: The price is $299.99
2020-05-09 00:39:51 [root] INFO: status: Sold Out
2020-05-09 00:39:55 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:39:55 [root] INFO: The price is $249.99
2020-05-09 00:39:55 [root] INFO: status: Sold Out
2020-05-09 00:39:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:39:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573440,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.679891,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 39, 55, 234750),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 39, 38, 554859)}
2020-05-09 00:39:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:40:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:40:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:40:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:40:18 [scrapy.extensions.telnet] INFO: Telnet Password: 87df0d3549fc5477
2020-05-09 00:40:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:40:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:40:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:40:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:40:24 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:40:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:40:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:40:34 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:40:34 [root] INFO: The price is $249.99
2020-05-09 00:40:34 [root] INFO: status: Sold Out
2020-05-09 00:40:37 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:40:37 [root] INFO: The price is $299.99
2020-05-09 00:40:37 [root] INFO: status: Sold Out
2020-05-09 00:40:39 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:40:39 [root] INFO: The price is $399.99
2020-05-09 00:40:39 [root] INFO: status: Sold Out
2020-05-09 00:40:42 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:40:42 [root] INFO: The price is $299.99
2020-05-09 00:40:42 [root] INFO: status: Sold Out
2020-05-09 00:40:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:40:44 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:40:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573412,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.979924,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 40, 44, 456601),
 'log_count/ERROR': 1,
 'log_count/INFO': 22,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 40, 24, 476677)}
2020-05-09 00:40:44 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:41:09 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:41:09 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:41:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:41:09 [scrapy.extensions.telnet] INFO: Telnet Password: 2a5714cd8a46a1a2
2020-05-09 00:41:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:41:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:41:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:41:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:41:15 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:41:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:41:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:41:23 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:41:23 [root] INFO: The price is $399.99
2020-05-09 00:41:23 [root] INFO: status: Sold Out
2020-05-09 00:41:27 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:41:27 [root] INFO: The price is $199.99
2020-05-09 00:41:27 [root] INFO: status: Sold Out
2020-05-09 00:41:30 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:41:30 [root] INFO: The price is $249.99
2020-05-09 00:41:30 [root] INFO: status: Sold Out
2020-05-09 00:41:32 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:41:32 [root] INFO: The price is $299.99
2020-05-09 00:41:32 [root] INFO: status: Sold Out
2020-05-09 00:41:34 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:41:34 [root] INFO: The price is $299.99
2020-05-09 00:41:34 [root] INFO: status: Sold Out
2020-05-09 00:41:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:41:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573434,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.183346,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 41, 34, 840248),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 41, 15, 656902)}
2020-05-09 00:41:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:41:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:41:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:41:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:41:58 [scrapy.extensions.telnet] INFO: Telnet Password: 5603e0805a06357d
2020-05-09 00:41:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:42:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:42:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:42:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:42:04 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:42:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:42:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:42:10 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:42:10 [root] INFO: The price is $299.99
2020-05-09 00:42:10 [root] INFO: status: Sold Out
2020-05-09 00:42:13 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:42:13 [root] INFO: The price is $199.99
2020-05-09 00:42:13 [root] INFO: status: Sold Out
2020-05-09 00:42:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:42:20 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CD9A4808>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d2b42defc02fb6f1ab4480130d77879e/url
2020-05-09 00:42:22 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CD81E608>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d2b42defc02fb6f1ab4480130d77879e/url
2020-05-09 00:42:24 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CD781688>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d2b42defc02fb6f1ab4480130d77879e/url
2020-05-09 00:42:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000245CEC43888>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=62549): Max retries exceeded with url: /session/d2b42defc02fb6f1ab4480130d77879e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CEC43888>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:42:28 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CD7FA548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d2b42defc02fb6f1ab4480130d77879e/url
2020-05-09 00:42:30 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CEC40F48>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d2b42defc02fb6f1ab4480130d77879e/url
2020-05-09 00:42:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CEC40748>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d2b42defc02fb6f1ab4480130d77879e/url
2020-05-09 00:42:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000245CD9BE9C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=62549): Max retries exceeded with url: /session/d2b42defc02fb6f1ab4480130d77879e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000245CD9BE9C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:42:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:42:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573442,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 30.190343,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 42, 34, 305611),
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'log_count/WARNING': 6,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 2,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 42, 4, 115268)}
2020-05-09 00:42:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:42:59 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:42:59 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:42:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:42:59 [scrapy.extensions.telnet] INFO: Telnet Password: d360ba13b8aafa3a
2020-05-09 00:42:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:43:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:43:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:43:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:43:05 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:43:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:43:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:43:11 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:43:11 [root] INFO: The price is $199.99
2020-05-09 00:43:11 [root] INFO: status: Add to Cart
2020-05-09 00:43:14 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:43:14 [root] INFO: The price is $299.99
2020-05-09 00:43:14 [root] INFO: status: Sold Out
2020-05-09 00:43:17 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:43:17 [root] INFO: The price is $249.99
2020-05-09 00:43:17 [root] INFO: status: Sold Out
2020-05-09 00:43:19 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:43:19 [root] INFO: The price is $299.99
2020-05-09 00:43:19 [root] INFO: status: Sold Out
2020-05-09 00:43:21 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:43:21 [root] INFO: The price is $399.99
2020-05-09 00:43:21 [root] INFO: status: Sold Out
2020-05-09 00:43:21 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:43:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573431,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.211063,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 43, 21, 770178),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 43, 5, 559115)}
2020-05-09 00:43:21 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:43:45 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:43:45 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:43:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:43:45 [scrapy.extensions.telnet] INFO: Telnet Password: 0c59968e29aacb3c
2020-05-09 00:43:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:43:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:43:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:43:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:43:50 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:43:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:43:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:43:57 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:43:57 [root] INFO: The price is $299.99
2020-05-09 00:43:57 [root] INFO: status: Sold Out
2020-05-09 00:44:00 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:44:00 [root] INFO: The price is $299.99
2020-05-09 00:44:00 [root] INFO: status: Sold Out
2020-05-09 00:44:03 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:44:03 [root] INFO: The price is $199.99
2020-05-09 00:44:03 [root] INFO: status: Sold Out
2020-05-09 00:44:05 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:44:05 [root] INFO: The price is $249.99
2020-05-09 00:44:05 [root] INFO: status: Sold Out
2020-05-09 00:44:08 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:44:08 [root] INFO: The price is $399.99
2020-05-09 00:44:08 [root] INFO: status: Sold Out
2020-05-09 00:44:08 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:44:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573438,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.122818,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 44, 8, 123707),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 43, 51, 889)}
2020-05-09 00:44:08 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:44:31 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:44:31 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:44:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:44:31 [scrapy.extensions.telnet] INFO: Telnet Password: e94b09c486c9f0e6
2020-05-09 00:44:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:44:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:44:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:44:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:44:37 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:44:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:44:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:44:46 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:44:46 [root] INFO: The price is $249.99
2020-05-09 00:44:46 [root] INFO: status: Sold Out
2020-05-09 00:44:49 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:44:49 [root] INFO: The price is $399.99
2020-05-09 00:44:49 [root] INFO: status: Sold Out
2020-05-09 00:44:52 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:44:52 [root] INFO: The price is $199.99
2020-05-09 00:44:52 [root] INFO: status: Sold Out
2020-05-09 00:44:54 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:44:54 [root] INFO: The price is $299.99
2020-05-09 00:44:54 [root] INFO: status: Sold Out
2020-05-09 00:44:57 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:44:57 [root] INFO: The price is $299.99
2020-05-09 00:44:57 [root] INFO: status: Sold Out
2020-05-09 00:44:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:44:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573449,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.87867,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 44, 57, 200647),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 44, 37, 321977)}
2020-05-09 00:44:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:45:20 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:45:20 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:45:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:45:20 [scrapy.extensions.telnet] INFO: Telnet Password: 01f352007af92979
2020-05-09 00:45:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:45:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:45:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:45:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:45:26 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:45:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:45:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:45:33 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:45:33 [root] INFO: The price is $249.99
2020-05-09 00:45:33 [root] INFO: status: Sold Out
2020-05-09 00:45:36 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:45:36 [root] INFO: The price is $299.99
2020-05-09 00:45:36 [root] INFO: status: Sold Out
2020-05-09 00:45:39 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:45:39 [root] INFO: The price is $399.99
2020-05-09 00:45:39 [root] INFO: status: Sold Out
2020-05-09 00:45:41 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:45:41 [root] INFO: The price is $199.99
2020-05-09 00:45:41 [root] INFO: status: Sold Out
2020-05-09 00:45:43 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:45:43 [root] INFO: The price is $299.99
2020-05-09 00:45:43 [root] INFO: status: Sold Out
2020-05-09 00:45:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:45:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573440,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.285504,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 45, 43, 674235),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 45, 26, 388731)}
2020-05-09 00:45:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:46:07 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:46:07 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:46:07 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:46:07 [scrapy.extensions.telnet] INFO: Telnet Password: c17d83b04718da07
2020-05-09 00:46:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:46:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:46:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:46:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:46:12 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:46:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:46:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:46:20 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:46:20 [root] INFO: The price is $299.99
2020-05-09 00:46:20 [root] INFO: status: Sold Out
2020-05-09 00:46:23 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:46:23 [root] INFO: The price is $199.99
2020-05-09 00:46:23 [root] INFO: status: Sold Out
2020-05-09 00:46:27 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:46:27 [root] INFO: The price is $249.99
2020-05-09 00:46:27 [root] INFO: status: Sold Out
2020-05-09 00:46:30 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:46:30 [root] INFO: The price is $399.99
2020-05-09 00:46:30 [root] INFO: status: Sold Out
2020-05-09 00:46:32 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:46:32 [root] INFO: The price is $299.99
2020-05-09 00:46:32 [root] INFO: status: Sold Out
2020-05-09 00:46:32 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:46:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573443,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.884378,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 46, 32, 821159),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 46, 12, 936781)}
2020-05-09 00:46:32 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:46:56 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:46:56 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:46:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:46:56 [scrapy.extensions.telnet] INFO: Telnet Password: 7e4ddfcd41ef66ef
2020-05-09 00:46:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:47:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:47:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:47:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:47:02 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:47:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:47:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:47:07 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:47:07 [root] INFO: The price is $199.99
2020-05-09 00:47:07 [root] INFO: status: Add to Cart
2020-05-09 00:47:10 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:47:10 [root] INFO: The price is $299.99
2020-05-09 00:47:10 [root] INFO: status: Sold Out
2020-05-09 00:47:14 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:47:14 [root] INFO: The price is $249.99
2020-05-09 00:47:14 [root] INFO: status: Sold Out
2020-05-09 00:47:16 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:47:16 [root] INFO: The price is $299.99
2020-05-09 00:47:16 [root] INFO: status: Sold Out
2020-05-09 00:47:19 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:47:19 [root] INFO: The price is $399.99
2020-05-09 00:47:19 [root] INFO: status: Sold Out
2020-05-09 00:47:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:47:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573438,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.96528,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 47, 19, 35186),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 47, 2, 69906)}
2020-05-09 00:47:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:47:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:47:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:47:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:47:42 [scrapy.extensions.telnet] INFO: Telnet Password: dca3d21ba59f893b
2020-05-09 00:47:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:47:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:47:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:47:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:47:48 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:47:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:47:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:47:55 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:47:55 [root] INFO: The price is $399.99
2020-05-09 00:47:55 [root] INFO: status: Sold Out
2020-05-09 00:47:59 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:47:59 [root] INFO: The price is $249.99
2020-05-09 00:47:59 [root] INFO: status: Sold Out
2020-05-09 00:48:02 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:48:02 [root] INFO: The price is $199.99
2020-05-09 00:48:02 [root] INFO: status: Sold Out
2020-05-09 00:48:05 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:48:05 [root] INFO: The price is $299.99
2020-05-09 00:48:05 [root] INFO: status: Sold Out
2020-05-09 00:48:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:48:07 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:48:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573449,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.147027,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 48, 7, 479646),
 'log_count/ERROR': 1,
 'log_count/INFO': 22,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 47, 48, 332619)}
2020-05-09 00:48:07 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:48:32 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:48:32 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:48:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:48:32 [scrapy.extensions.telnet] INFO: Telnet Password: 3c338f0ca8bfab77
2020-05-09 00:48:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:48:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:48:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:48:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:48:38 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:48:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:48:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:48:44 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:48:44 [root] INFO: The price is $299.99
2020-05-09 00:48:44 [root] INFO: status: Sold Out
2020-05-09 00:48:48 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:48:48 [root] INFO: The price is $399.99
2020-05-09 00:48:48 [root] INFO: status: Sold Out
2020-05-09 00:48:51 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:48:51 [root] INFO: The price is $249.99
2020-05-09 00:48:51 [root] INFO: status: Sold Out
2020-05-09 00:48:54 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:48:54 [root] INFO: The price is $199.99
2020-05-09 00:48:54 [root] INFO: status: Sold Out
2020-05-09 00:48:56 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:48:56 [root] INFO: The price is $299.99
2020-05-09 00:48:56 [root] INFO: status: Sold Out
2020-05-09 00:48:56 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:48:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573439,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.947867,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 48, 56, 713621),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 48, 38, 765754)}
2020-05-09 00:48:56 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:49:20 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:49:20 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:49:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:49:20 [scrapy.extensions.telnet] INFO: Telnet Password: 58a9fb240349f78b
2020-05-09 00:49:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:49:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:49:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:49:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:49:26 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:49:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:49:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:49:33 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:49:33 [root] INFO: The price is $249.99
2020-05-09 00:49:33 [root] INFO: status: Sold Out
2020-05-09 00:49:36 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:49:36 [root] INFO: The price is $299.99
2020-05-09 00:49:36 [root] INFO: status: Sold Out
2020-05-09 00:49:38 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:49:38 [root] INFO: The price is $399.99
2020-05-09 00:49:38 [root] INFO: status: Sold Out
2020-05-09 00:49:40 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:49:40 [root] INFO: The price is $199.99
2020-05-09 00:49:40 [root] INFO: status: Sold Out
2020-05-09 00:49:43 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:49:43 [root] INFO: The price is $299.99
2020-05-09 00:49:43 [root] INFO: status: Sold Out
2020-05-09 00:49:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:49:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573443,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.031771,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 49, 43, 117707),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 49, 26, 85936)}
2020-05-09 00:49:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:50:06 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:50:06 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:50:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:50:06 [scrapy.extensions.telnet] INFO: Telnet Password: f5cc16092f0365c1
2020-05-09 00:50:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:50:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:50:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:50:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:50:12 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:50:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:50:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:50:18 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:50:18 [root] INFO: The price is $299.99
2020-05-09 00:50:18 [root] INFO: status: Sold Out
2020-05-09 00:50:21 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:50:21 [root] INFO: The price is $199.99
2020-05-09 00:50:21 [root] INFO: status: Sold Out
2020-05-09 00:50:23 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:50:23 [root] INFO: The price is $399.99
2020-05-09 00:50:23 [root] INFO: status: Sold Out
2020-05-09 00:50:27 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:50:27 [root] INFO: The price is $249.99
2020-05-09 00:50:27 [root] INFO: status: Sold Out
2020-05-09 00:50:29 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:50:29 [root] INFO: The price is $299.99
2020-05-09 00:50:29 [root] INFO: status: Sold Out
2020-05-09 00:50:29 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:50:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573421,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.263776,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 50, 29, 629205),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 50, 12, 365429)}
2020-05-09 00:50:29 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:50:53 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:50:53 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:50:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:50:53 [scrapy.extensions.telnet] INFO: Telnet Password: 2b5e91428fb8618d
2020-05-09 00:50:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:50:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:50:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:50:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:50:58 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:50:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:50:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:51:05 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:51:05 [root] INFO: The price is $299.99
2020-05-09 00:51:05 [root] INFO: status: Sold Out
2020-05-09 00:51:09 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:51:09 [root] INFO: The price is $299.99
2020-05-09 00:51:09 [root] INFO: status: Sold Out
2020-05-09 00:51:12 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:51:12 [root] INFO: The price is $399.99
2020-05-09 00:51:12 [root] INFO: status: Sold Out
2020-05-09 00:51:16 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:51:16 [root] INFO: The price is $249.99
2020-05-09 00:51:16 [root] INFO: status: Sold Out
2020-05-09 00:51:18 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:51:18 [root] INFO: The price is $199.99
2020-05-09 00:51:18 [root] INFO: status: Sold Out
2020-05-09 00:51:18 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:51:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573423,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.726974,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 51, 18, 693979),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 50, 58, 967005)}
2020-05-09 00:51:18 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:51:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:51:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:51:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:51:42 [scrapy.extensions.telnet] INFO: Telnet Password: d828e66022e401e6
2020-05-09 00:51:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:51:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:51:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:51:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:51:47 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:51:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:51:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:51:54 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:51:54 [root] INFO: The price is $299.99
2020-05-09 00:51:54 [root] INFO: status: Sold Out
2020-05-09 00:51:58 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:51:58 [root] INFO: The price is $299.99
2020-05-09 00:51:58 [root] INFO: status: Sold Out
2020-05-09 00:52:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:52:02 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCD95D80C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1d026df12f33e953cb4cd71ce63c9688/url
2020-05-09 00:52:04 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCDAAB5C88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1d026df12f33e953cb4cd71ce63c9688/url
2020-05-09 00:52:06 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCDAAB5388>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1d026df12f33e953cb4cd71ce63c9688/url
2020-05-09 00:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001CCDAAB5188>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=64309): Max retries exceeded with url: /session/1d026df12f33e953cb4cd71ce63c9688/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCDAAB5188>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:52:10 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCD95D8308>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1d026df12f33e953cb4cd71ce63c9688/url
2020-05-09 00:52:12 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCDAAC1588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1d026df12f33e953cb4cd71ce63c9688/url
2020-05-09 00:52:14 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCDAAC1F48>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1d026df12f33e953cb4cd71ce63c9688/url
2020-05-09 00:52:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001CCD980D548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=64309): Max retries exceeded with url: /session/1d026df12f33e953cb4cd71ce63c9688/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CCD980D548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:52:16 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:52:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573426,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 28.846098,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 52, 16, 809529),
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'log_count/WARNING': 6,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 2,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 51, 47, 963431)}
2020-05-09 00:52:16 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:52:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:52:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:52:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:52:42 [scrapy.extensions.telnet] INFO: Telnet Password: 569f6262e27ea9f7
2020-05-09 00:52:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:52:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:52:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:52:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:52:48 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:52:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:52:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:52:57 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:52:57 [root] INFO: The price is $299.99
2020-05-09 00:52:57 [root] INFO: status: Sold Out
2020-05-09 00:53:00 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:53:00 [root] INFO: The price is $299.99
2020-05-09 00:53:00 [root] INFO: status: Sold Out
2020-05-09 00:53:05 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:53:05 [root] INFO: The price is $249.99
2020-05-09 00:53:05 [root] INFO: status: Sold Out
2020-05-09 00:53:08 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:53:08 [root] INFO: The price is $399.99
2020-05-09 00:53:08 [root] INFO: status: Sold Out
2020-05-09 00:53:11 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:53:11 [root] INFO: The price is $199.99
2020-05-09 00:53:11 [root] INFO: status: Sold Out
2020-05-09 00:53:11 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:53:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573425,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 23.228728,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 53, 11, 349671),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 52, 48, 120943)}
2020-05-09 00:53:11 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:53:34 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:53:34 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:53:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:53:34 [scrapy.extensions.telnet] INFO: Telnet Password: 1c07987985d94e98
2020-05-09 00:53:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:53:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:53:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:53:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:53:40 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:53:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:53:48 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:53:48 [root] INFO: The price is $299.99
2020-05-09 00:53:48 [root] INFO: status: Sold Out
2020-05-09 00:53:51 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:53:51 [root] INFO: The price is $399.99
2020-05-09 00:53:51 [root] INFO: status: Sold Out
2020-05-09 00:53:55 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:53:55 [root] INFO: The price is $249.99
2020-05-09 00:53:55 [root] INFO: status: Sold Out
2020-05-09 00:53:57 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:53:57 [root] INFO: The price is $199.99
2020-05-09 00:53:57 [root] INFO: status: Sold Out
2020-05-09 00:54:00 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:54:00 [root] INFO: The price is $299.99
2020-05-09 00:54:00 [root] INFO: status: Sold Out
2020-05-09 00:54:00 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:54:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573436,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.333643,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 54, 0, 29745),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 53, 40, 696102)}
2020-05-09 00:54:00 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:54:23 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:54:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:54:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:54:23 [scrapy.extensions.telnet] INFO: Telnet Password: a2f5f868fe7faddf
2020-05-09 00:54:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:54:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:54:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:54:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:54:29 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:54:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:54:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:54:36 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:54:36 [root] INFO: The price is $199.99
2020-05-09 00:54:36 [root] INFO: status: Add to Cart
2020-05-09 00:54:39 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:54:39 [root] INFO: The price is $299.99
2020-05-09 00:54:39 [root] INFO: status: Sold Out
2020-05-09 00:54:42 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:54:42 [root] INFO: The price is $249.99
2020-05-09 00:54:42 [root] INFO: status: Sold Out
2020-05-09 00:54:45 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:54:45 [root] INFO: The price is $299.99
2020-05-09 00:54:45 [root] INFO: status: Sold Out
2020-05-09 00:54:47 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:54:47 [root] INFO: The price is $399.99
2020-05-09 00:54:47 [root] INFO: status: Sold Out
2020-05-09 00:54:47 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:54:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573443,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.7491,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 54, 47, 98306),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 54, 29, 349206)}
2020-05-09 00:54:47 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:55:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:55:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:55:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:55:10 [scrapy.extensions.telnet] INFO: Telnet Password: 272cad9a631fbe59
2020-05-09 00:55:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:55:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:55:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:55:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:55:16 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:55:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:55:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:55:24 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:55:24 [root] INFO: The price is $299.99
2020-05-09 00:55:24 [root] INFO: status: Sold Out
2020-05-09 00:55:26 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:55:26 [root] INFO: The price is $199.99
2020-05-09 00:55:26 [root] INFO: status: Sold Out
2020-05-09 00:55:29 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:55:29 [root] INFO: The price is $299.99
2020-05-09 00:55:29 [root] INFO: status: Sold Out
2020-05-09 00:55:31 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:55:31 [root] INFO: The price is $399.99
2020-05-09 00:55:31 [root] INFO: status: Sold Out
2020-05-09 00:55:34 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:55:34 [root] INFO: The price is $249.99
2020-05-09 00:55:34 [root] INFO: status: Sold Out
2020-05-09 00:55:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:55:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573439,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.626986,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 55, 34, 369580),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 55, 16, 742594)}
2020-05-09 00:55:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:55:57 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:55:57 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:55:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:55:57 [scrapy.extensions.telnet] INFO: Telnet Password: 991b404ce5851af2
2020-05-09 00:55:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:56:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:56:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:56:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:56:03 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:56:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:56:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:56:09 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:56:09 [root] INFO: The price is $249.99
2020-05-09 00:56:09 [root] INFO: status: Sold Out
2020-05-09 00:56:12 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:56:12 [root] INFO: The price is $299.99
2020-05-09 00:56:12 [root] INFO: status: Sold Out
2020-05-09 00:56:14 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:56:14 [root] INFO: The price is $399.99
2020-05-09 00:56:14 [root] INFO: status: Sold Out
2020-05-09 00:56:16 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:56:16 [root] INFO: The price is $199.99
2020-05-09 00:56:16 [root] INFO: status: Add to Cart
2020-05-09 00:56:19 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:56:19 [root] INFO: The price is $299.99
2020-05-09 00:56:19 [root] INFO: status: Sold Out
2020-05-09 00:56:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:56:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573442,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 15.530989,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 56, 19, 200459),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 56, 3, 669470)}
2020-05-09 00:56:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:56:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:56:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:56:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:56:42 [scrapy.extensions.telnet] INFO: Telnet Password: a36514c712bf4b40
2020-05-09 00:56:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:56:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:56:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:56:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:56:48 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:56:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:56:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:56:54 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:56:54 [root] INFO: The price is $399.99
2020-05-09 00:56:54 [root] INFO: status: Sold Out
2020-05-09 00:56:58 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:56:58 [root] INFO: The price is $299.99
2020-05-09 00:56:58 [root] INFO: status: Sold Out
2020-05-09 00:57:01 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:57:01 [root] INFO: The price is $249.99
2020-05-09 00:57:01 [root] INFO: status: Sold Out
2020-05-09 00:57:04 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:57:04 [root] INFO: The price is $199.99
2020-05-09 00:57:04 [root] INFO: status: Add to Cart
2020-05-09 00:57:07 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:57:07 [root] INFO: The price is $299.99
2020-05-09 00:57:07 [root] INFO: status: Sold Out
2020-05-09 00:57:07 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:57:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573421,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 18.996391,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 57, 7, 497517),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 56, 48, 501126)}
2020-05-09 00:57:07 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:57:30 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:57:30 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:57:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:57:30 [scrapy.extensions.telnet] INFO: Telnet Password: d328ccee41fbeb70
2020-05-09 00:57:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:57:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:57:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:57:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:57:36 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:57:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:57:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:57:42 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:57:42 [root] INFO: The price is $399.99
2020-05-09 00:57:42 [root] INFO: status: Sold Out
2020-05-09 00:57:45 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:57:45 [root] INFO: The price is $299.99
2020-05-09 00:57:45 [root] INFO: status: Sold Out
2020-05-09 00:57:48 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:57:48 [root] INFO: The price is $299.99
2020-05-09 00:57:48 [root] INFO: status: Sold Out
2020-05-09 00:57:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:57:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016C4BB00BC8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d4d04cc4bfe6627d648f67beb6fcbfc3/url
2020-05-09 00:57:54 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016C4D2790C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d4d04cc4bfe6627d648f67beb6fcbfc3/url
2020-05-09 00:57:56 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016C4D2791C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/d4d04cc4bfe6627d648f67beb6fcbfc3/url
2020-05-09 00:57:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016C4D279888>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=65399): Max retries exceeded with url: /session/d4d04cc4bfe6627d648f67beb6fcbfc3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016C4D279888>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:57:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:57:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573449,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.253707,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 57, 59, 50105),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 57, 36, 796398)}
2020-05-09 00:57:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:58:24 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:58:24 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:58:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:58:24 [scrapy.extensions.telnet] INFO: Telnet Password: 7611f7005119ea34
2020-05-09 00:58:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:58:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:58:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:58:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:58:30 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:58:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:58:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:58:37 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:58:37 [root] INFO: The price is $299.99
2020-05-09 00:58:37 [root] INFO: status: Sold Out
2020-05-09 00:58:40 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:58:40 [root] INFO: The price is $199.99
2020-05-09 00:58:40 [root] INFO: status: Add to Cart
2020-05-09 00:58:42 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:58:42 [root] INFO: The price is $399.99
2020-05-09 00:58:42 [root] INFO: status: Sold Out
2020-05-09 00:58:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 00:58:46 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000209D902DA88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/19085c4c5b6442186be2f8fafa9a3ec6/url
2020-05-09 00:58:48 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000209D79F7988>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/19085c4c5b6442186be2f8fafa9a3ec6/url
2020-05-09 00:58:50 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000209D79FD2C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/19085c4c5b6442186be2f8fafa9a3ec6/url
2020-05-09 00:58:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000209D79FD348>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49184): Max retries exceeded with url: /session/19085c4c5b6442186be2f8fafa9a3ec6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000209D79FD348>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 00:58:52 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:58:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573442,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.365874,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 58, 52, 734633),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 5, 58, 30, 368759)}
2020-05-09 00:58:52 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 00:59:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 00:59:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 00:59:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 00:59:18 [scrapy.extensions.telnet] INFO: Telnet Password: 9586aaef93b320eb
2020-05-09 00:59:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 00:59:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 00:59:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 00:59:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 00:59:24 [scrapy.core.engine] INFO: Spider opened
2020-05-09 00:59:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 00:59:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 00:59:31 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 00:59:31 [root] INFO: The price is $399.99
2020-05-09 00:59:31 [root] INFO: status: Sold Out
2020-05-09 00:59:35 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 00:59:35 [root] INFO: The price is $199.99
2020-05-09 00:59:35 [root] INFO: status: Add to Cart
2020-05-09 00:59:38 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 00:59:38 [root] INFO: The price is $299.99
2020-05-09 00:59:38 [root] INFO: status: Sold Out
2020-05-09 00:59:41 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 00:59:41 [root] INFO: The price is $249.99
2020-05-09 00:59:41 [root] INFO: status: Sold Out
2020-05-09 00:59:45 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 00:59:45 [root] INFO: The price is $299.99
2020-05-09 00:59:45 [root] INFO: status: Sold Out
2020-05-09 00:59:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 00:59:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573424,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.222843,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 5, 59, 45, 337876),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 5, 59, 24, 115033)}
2020-05-09 00:59:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:00:08 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:00:08 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:00:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:00:08 [scrapy.extensions.telnet] INFO: Telnet Password: 4af3b2a564a2df05
2020-05-09 01:00:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:00:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:00:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:00:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:00:14 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:00:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:00:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:00:20 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:00:20 [root] INFO: The price is $399.99
2020-05-09 01:00:20 [root] INFO: status: Sold Out
2020-05-09 01:00:24 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:00:24 [root] INFO: The price is $249.99
2020-05-09 01:00:24 [root] INFO: status: Sold Out
2020-05-09 01:00:27 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:00:27 [root] INFO: The price is $299.99
2020-05-09 01:00:27 [root] INFO: status: Sold Out
2020-05-09 01:00:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:00:31 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023DE67934C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f52dd9c96dbf81fba10e78e9208c0c54/url
2020-05-09 01:00:33 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023DE7DBA088>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f52dd9c96dbf81fba10e78e9208c0c54/url
2020-05-09 01:00:35 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023DE7DBA188>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f52dd9c96dbf81fba10e78e9208c0c54/url
2020-05-09 01:00:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000023DE7DBA848>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49596): Max retries exceeded with url: /session/f52dd9c96dbf81fba10e78e9208c0c54/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023DE7DBA848>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:00:37 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:00:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573438,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 23.030043,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 0, 37, 863565),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 0, 14, 833522)}
2020-05-09 01:00:37 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:01:03 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:01:03 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:01:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:01:03 [scrapy.extensions.telnet] INFO: Telnet Password: 7833a259f3fdf242
2020-05-09 01:01:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:01:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:01:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:01:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:01:09 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:01:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:01:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:01:16 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:01:16 [root] INFO: The price is $299.99
2020-05-09 01:01:16 [root] INFO: status: Sold Out
2020-05-09 01:01:20 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:01:20 [root] INFO: The price is $399.99
2020-05-09 01:01:20 [root] INFO: status: Sold Out
2020-05-09 01:01:23 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:01:23 [root] INFO: The price is $299.99
2020-05-09 01:01:23 [root] INFO: status: Sold Out
2020-05-09 01:01:28 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:01:28 [root] INFO: The price is $249.99
2020-05-09 01:01:28 [root] INFO: status: Sold Out
2020-05-09 01:01:30 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:01:30 [root] INFO: The price is $199.99
2020-05-09 01:01:30 [root] INFO: status: Add to Cart
2020-05-09 01:01:30 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:01:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573437,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.274922,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 1, 30, 512176),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 1, 9, 237254)}
2020-05-09 01:01:30 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:01:54 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:01:54 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:01:54 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:01:54 [scrapy.extensions.telnet] INFO: Telnet Password: 0f1c8fc2fba5482e
2020-05-09 01:01:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:01:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:01:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:01:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:01:59 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:01:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:01:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:02:07 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:02:07 [root] INFO: The price is $199.99
2020-05-09 01:02:07 [root] INFO: status: Add to Cart
2020-05-09 01:02:11 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:02:11 [root] INFO: The price is $299.99
2020-05-09 01:02:11 [root] INFO: status: Sold Out
2020-05-09 01:02:13 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:02:13 [root] INFO: The price is $399.99
2020-05-09 01:02:13 [root] INFO: status: Sold Out
2020-05-09 01:02:16 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:02:16 [root] INFO: The price is $249.99
2020-05-09 01:02:16 [root] INFO: status: Sold Out
2020-05-09 01:02:19 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:02:19 [root] INFO: The price is $299.99
2020-05-09 01:02:19 [root] INFO: status: Sold Out
2020-05-09 01:02:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:02:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573444,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.070592,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 2, 19, 68122),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 1, 59, 997530)}
2020-05-09 01:02:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:02:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:02:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:02:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:02:42 [scrapy.extensions.telnet] INFO: Telnet Password: 054d0702c63b0896
2020-05-09 01:02:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:02:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:02:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:02:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:02:48 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:02:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:02:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:02:56 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:02:56 [root] INFO: The price is $299.99
2020-05-09 01:02:56 [root] INFO: status: Sold Out
2020-05-09 01:02:59 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:02:59 [root] INFO: The price is $399.99
2020-05-09 01:02:59 [root] INFO: status: Sold Out
2020-05-09 01:03:03 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:03:03 [root] INFO: The price is $249.99
2020-05-09 01:03:03 [root] INFO: status: Sold Out
2020-05-09 01:03:06 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:03:06 [root] INFO: The price is $199.99
2020-05-09 01:03:06 [root] INFO: status: Add to Cart
2020-05-09 01:03:09 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:03:09 [root] INFO: The price is $299.99
2020-05-09 01:03:09 [root] INFO: status: Sold Out
2020-05-09 01:03:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:03:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573450,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.758976,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 3, 9, 282305),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 2, 48, 523329)}
2020-05-09 01:03:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:03:32 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:03:32 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:03:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:03:32 [scrapy.extensions.telnet] INFO: Telnet Password: c4ccd8d2cb402241
2020-05-09 01:03:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:03:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:03:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:03:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:03:38 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:03:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:03:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:03:45 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:03:45 [root] INFO: The price is $199.99
2020-05-09 01:03:45 [root] INFO: status: Add to Cart
2020-05-09 01:03:48 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:03:48 [root] INFO: The price is $299.99
2020-05-09 01:03:48 [root] INFO: status: Sold Out
2020-05-09 01:03:52 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:03:52 [root] INFO: The price is $249.99
2020-05-09 01:03:52 [root] INFO: status: Sold Out
2020-05-09 01:03:54 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:03:54 [root] INFO: The price is $399.99
2020-05-09 01:03:54 [root] INFO: status: Sold Out
2020-05-09 01:03:56 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:03:56 [root] INFO: The price is $299.99
2020-05-09 01:03:56 [root] INFO: status: Sold Out
2020-05-09 01:03:56 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:03:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573443,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.414567,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 3, 56, 198043),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 3, 38, 783476)}
2020-05-09 01:03:56 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:04:19 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:04:19 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:04:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:04:19 [scrapy.extensions.telnet] INFO: Telnet Password: 89e89f591a583d8c
2020-05-09 01:04:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:04:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:04:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:04:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:04:25 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:04:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:04:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:04:39 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:04:39 [root] INFO: The price is $399.99
2020-05-09 01:04:39 [root] INFO: status: Sold Out
2020-05-09 01:04:45 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:04:45 [root] INFO: The price is $199.99
2020-05-09 01:04:45 [root] INFO: status: Add to Cart
2020-05-09 01:04:48 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:04:48 [root] INFO: The price is $299.99
2020-05-09 01:04:48 [root] INFO: status: Sold Out
2020-05-09 01:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:04:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B89DABA908>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fecc5af2fb1b2e7b6927b0d35a13ce94/url
2020-05-09 01:04:54 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B89C487808>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fecc5af2fb1b2e7b6927b0d35a13ce94/url
2020-05-09 01:04:56 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B89C48C148>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/fecc5af2fb1b2e7b6927b0d35a13ce94/url
2020-05-09 01:04:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B89C48C208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=50463): Max retries exceeded with url: /session/fecc5af2fb1b2e7b6927b0d35a13ce94/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B89C48C208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:04:58 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:04:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573463,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 33.197549,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 4, 58, 668986),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 4, 25, 471437)}
2020-05-09 01:04:58 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:05:23 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:05:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:05:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:05:23 [scrapy.extensions.telnet] INFO: Telnet Password: a873f57cfedbfdec
2020-05-09 01:05:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:05:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:05:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:05:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:05:29 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:05:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:05:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:05:36 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:05:36 [root] INFO: The price is $249.99
2020-05-09 01:05:36 [root] INFO: status: Sold Out
2020-05-09 01:05:41 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:05:41 [root] INFO: The price is $299.99
2020-05-09 01:05:41 [root] INFO: status: Sold Out
2020-05-09 01:05:43 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:05:43 [root] INFO: The price is $299.99
2020-05-09 01:05:43 [root] INFO: status: Sold Out
2020-05-09 01:05:46 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:05:46 [root] INFO: The price is $199.99
2020-05-09 01:05:46 [root] INFO: status: Add to Cart
2020-05-09 01:05:55 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:05:55 [root] INFO: The price is $399.99
2020-05-09 01:05:55 [root] INFO: status: Sold Out
2020-05-09 01:05:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:05:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573452,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 25.795571,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 5, 55, 442673),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 5, 29, 647102)}
2020-05-09 01:05:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:06:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:06:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:06:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:06:18 [scrapy.extensions.telnet] INFO: Telnet Password: 97dd027ad4ec0ad4
2020-05-09 01:06:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:06:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:06:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:06:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:06:24 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:06:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:06:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:06:29 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:06:29 [root] INFO: The price is $399.99
2020-05-09 01:06:29 [root] INFO: status: Sold Out
2020-05-09 01:06:33 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:06:33 [root] INFO: The price is $249.99
2020-05-09 01:06:33 [root] INFO: status: Sold Out
2020-05-09 01:06:35 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:06:35 [root] INFO: The price is $299.99
2020-05-09 01:06:35 [root] INFO: status: Sold Out
2020-05-09 01:06:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:06:39 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025F9C58B848>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/3c6aaac032054e4668df853e151b91fc/url
2020-05-09 01:06:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025F9AF58788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/3c6aaac032054e4668df853e151b91fc/url
2020-05-09 01:06:43 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025F9AF5D0C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/3c6aaac032054e4668df853e151b91fc/url
2020-05-09 01:06:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000025F9AF5D188>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=50735): Max retries exceeded with url: /session/3c6aaac032054e4668df853e151b91fc/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025F9AF5D188>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:06:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:06:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573451,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.791588,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 6, 45, 318715),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 6, 24, 527127)}
2020-05-09 01:06:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:07:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:07:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:07:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:07:10 [scrapy.extensions.telnet] INFO: Telnet Password: 1e47e9a267a7103a
2020-05-09 01:07:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:07:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:07:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:07:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:07:16 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:07:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:07:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:07:24 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:07:24 [root] INFO: The price is $299.99
2020-05-09 01:07:24 [root] INFO: status: Sold Out
2020-05-09 01:07:27 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:07:27 [root] INFO: The price is $199.99
2020-05-09 01:07:27 [root] INFO: status: Add to Cart
2020-05-09 01:07:30 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:07:30 [root] INFO: The price is $249.99
2020-05-09 01:07:30 [root] INFO: status: Sold Out
2020-05-09 01:07:32 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:07:32 [root] INFO: The price is $299.99
2020-05-09 01:07:32 [root] INFO: status: Sold Out
2020-05-09 01:07:37 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:07:37 [root] INFO: The price is $399.99
2020-05-09 01:07:37 [root] INFO: status: Sold Out
2020-05-09 01:07:37 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:07:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573417,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.598341,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 7, 37, 984654),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 7, 16, 386313)}
2020-05-09 01:07:37 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:08:01 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:08:01 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:08:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:08:01 [scrapy.extensions.telnet] INFO: Telnet Password: 0c7c7a5b00161c1d
2020-05-09 01:08:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:08:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:08:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:08:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:08:07 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:08:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:08:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:08:16 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:08:16 [root] INFO: The price is $299.99
2020-05-09 01:08:16 [root] INFO: status: Sold Out
2020-05-09 01:08:19 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:08:19 [root] INFO: The price is $399.99
2020-05-09 01:08:19 [root] INFO: status: Sold Out
2020-05-09 01:08:21 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:08:21 [root] INFO: The price is $199.99
2020-05-09 01:08:21 [root] INFO: status: Add to Cart
2020-05-09 01:08:23 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:08:23 [root] INFO: The price is $249.99
2020-05-09 01:08:23 [root] INFO: status: Sold Out
2020-05-09 01:08:26 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:08:26 [root] INFO: The price is $299.99
2020-05-09 01:08:26 [root] INFO: status: Sold Out
2020-05-09 01:08:26 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:08:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573441,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.277838,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 8, 26, 370394),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 8, 7, 92556)}
2020-05-09 01:08:26 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:08:49 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:08:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:08:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:08:49 [scrapy.extensions.telnet] INFO: Telnet Password: 7e9ef9af80e586ba
2020-05-09 01:08:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:08:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:08:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:08:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:08:55 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:08:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:08:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:09:12 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:09:12 [root] INFO: The price is $299.99
2020-05-09 01:09:12 [root] INFO: status: Sold Out
2020-05-09 01:09:19 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:09:19 [root] INFO: The price is $249.99
2020-05-09 01:09:19 [root] INFO: status: Sold Out
2020-05-09 01:09:26 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:09:26 [root] INFO: The price is $299.99
2020-05-09 01:09:26 [root] INFO: status: Sold Out
2020-05-09 01:09:32 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:09:32 [root] INFO: The price is $199.99
2020-05-09 01:09:32 [root] INFO: status: Add to Cart
2020-05-09 01:09:36 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:09:36 [root] INFO: The price is $399.99
2020-05-09 01:09:36 [root] INFO: status: Sold Out
2020-05-09 01:09:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:09:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573424,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 41.315029,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 9, 36, 673401),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 8, 55, 358372)}
2020-05-09 01:09:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:09:59 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:09:59 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:09:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:09:59 [scrapy.extensions.telnet] INFO: Telnet Password: 87d0d4016d4db579
2020-05-09 01:09:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:10:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:10:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:10:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:10:05 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:10:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:10:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:10:13 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:10:13 [root] INFO: The price is $299.99
2020-05-09 01:10:13 [root] INFO: status: Sold Out
2020-05-09 01:10:16 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:10:16 [root] INFO: The price is $299.99
2020-05-09 01:10:16 [root] INFO: status: Sold Out
2020-05-09 01:10:18 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:10:18 [root] INFO: The price is $199.99
2020-05-09 01:10:18 [root] INFO: status: Sold Out
2020-05-09 01:10:21 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:10:21 [root] INFO: The price is $399.99
2020-05-09 01:10:21 [root] INFO: status: Sold Out
2020-05-09 01:10:24 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:10:24 [root] INFO: The price is $249.99
2020-05-09 01:10:24 [root] INFO: status: Sold Out
2020-05-09 01:10:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:10:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573685,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 18.897995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 10, 24, 587255),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 10, 5, 689260)}
2020-05-09 01:10:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:10:47 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:10:47 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:10:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:10:47 [scrapy.extensions.telnet] INFO: Telnet Password: acde7f172d225561
2020-05-09 01:10:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:10:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:10:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:10:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:10:53 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:10:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:10:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:11:03 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:11:03 [root] INFO: The price is $249.99
2020-05-09 01:11:03 [root] INFO: status: Sold Out
2020-05-09 01:11:05 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:11:05 [root] INFO: The price is $399.99
2020-05-09 01:11:05 [root] INFO: status: Sold Out
2020-05-09 01:11:08 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:11:08 [root] INFO: The price is $199.99
2020-05-09 01:11:08 [root] INFO: status: Add to Cart
2020-05-09 01:11:11 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:11:11 [root] INFO: The price is $299.99
2020-05-09 01:11:11 [root] INFO: status: Sold Out
2020-05-09 01:11:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:11:13 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:11:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573437,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.004843,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 11, 13, 641824),
 'log_count/ERROR': 1,
 'log_count/INFO': 22,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 10, 53, 636981)}
2020-05-09 01:11:13 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:11:39 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:11:39 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:11:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:11:39 [scrapy.extensions.telnet] INFO: Telnet Password: 460ce53bf2973af8
2020-05-09 01:11:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:11:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:11:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:11:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:11:44 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:11:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:11:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:11:50 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:11:50 [root] INFO: The price is $199.99
2020-05-09 01:11:50 [root] INFO: status: Sold Out
2020-05-09 01:11:54 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:11:54 [root] INFO: The price is $249.99
2020-05-09 01:11:54 [root] INFO: status: Sold Out
2020-05-09 01:11:57 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:11:57 [root] INFO: The price is $299.99
2020-05-09 01:11:57 [root] INFO: status: Sold Out
2020-05-09 01:11:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:12:01 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000231C4EADD88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/8da0085fae537880e7318fcf48658ba5/url
2020-05-09 01:12:03 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000231C5045BC8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/8da0085fae537880e7318fcf48658ba5/url
2020-05-09 01:12:05 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000231C6492508>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/8da0085fae537880e7318fcf48658ba5/url
2020-05-09 01:12:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000231C64925C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=51485): Max retries exceeded with url: /session/8da0085fae537880e7318fcf48658ba5/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000231C64925C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:12:07 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:12:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573449,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.601898,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 12, 7, 427737),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 11, 44, 825839)}
2020-05-09 01:12:07 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:12:32 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:12:32 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:12:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:12:32 [scrapy.extensions.telnet] INFO: Telnet Password: da7a0c86116d63ec
2020-05-09 01:12:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:12:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:12:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:12:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:12:38 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:12:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:12:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:12:44 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:12:44 [root] INFO: The price is $399.99
2020-05-09 01:12:44 [root] INFO: status: Sold Out
2020-05-09 01:12:47 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:12:47 [root] INFO: The price is $299.99
2020-05-09 01:12:47 [root] INFO: status: Sold Out
2020-05-09 01:12:50 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:12:50 [root] INFO: The price is $249.99
2020-05-09 01:12:50 [root] INFO: status: Sold Out
2020-05-09 01:12:52 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:12:52 [root] INFO: The price is $199.99
2020-05-09 01:12:52 [root] INFO: status: Sold Out
2020-05-09 01:12:54 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:12:54 [root] INFO: The price is $299.99
2020-05-09 01:12:54 [root] INFO: status: Sold Out
2020-05-09 01:12:54 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:12:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573424,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.146233,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 12, 54, 745388),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 12, 38, 599155)}
2020-05-09 01:12:54 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:13:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:13:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:13:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:13:18 [scrapy.extensions.telnet] INFO: Telnet Password: e0a351a0a26d70fb
2020-05-09 01:13:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:13:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:13:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:13:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:13:23 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:13:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:13:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:13:34 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:13:34 [root] INFO: The price is $299.99
2020-05-09 01:13:34 [root] INFO: status: Sold Out
2020-05-09 01:13:38 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:13:38 [root] INFO: The price is $299.99
2020-05-09 01:13:38 [root] INFO: status: Sold Out
2020-05-09 01:13:41 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:13:41 [root] INFO: The price is $399.99
2020-05-09 01:13:41 [root] INFO: status: Sold Out
2020-05-09 01:13:44 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:13:44 [root] INFO: The price is $249.99
2020-05-09 01:13:44 [root] INFO: status: Sold Out
2020-05-09 01:13:46 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:13:46 [root] INFO: The price is $199.99
2020-05-09 01:13:46 [root] INFO: status: Sold Out
2020-05-09 01:13:46 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:13:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573446,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 23.009956,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 13, 46, 921490),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 13, 23, 911534)}
2020-05-09 01:13:46 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:14:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:14:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:14:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:14:10 [scrapy.extensions.telnet] INFO: Telnet Password: 22f49859278c454b
2020-05-09 01:14:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:14:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:14:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:14:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:14:16 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:14:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:14:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:14:23 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:14:23 [root] INFO: The price is $199.99
2020-05-09 01:14:23 [root] INFO: status: Sold Out
2020-05-09 01:14:26 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:14:26 [root] INFO: The price is $299.99
2020-05-09 01:14:26 [root] INFO: status: Sold Out
2020-05-09 01:14:31 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:14:31 [root] INFO: The price is $399.99
2020-05-09 01:14:31 [root] INFO: status: Sold Out
2020-05-09 01:14:34 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:14:34 [root] INFO: The price is $249.99
2020-05-09 01:14:34 [root] INFO: status: Sold Out
2020-05-09 01:14:36 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:14:36 [root] INFO: The price is $299.99
2020-05-09 01:14:36 [root] INFO: status: Sold Out
2020-05-09 01:14:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:14:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573430,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.676922,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 14, 36, 771973),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 14, 16, 95051)}
2020-05-09 01:14:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:15:00 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:15:00 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:15:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:15:00 [scrapy.extensions.telnet] INFO: Telnet Password: d98a68d97ba6ae52
2020-05-09 01:15:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:15:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:15:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:15:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:15:05 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:15:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:15:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:15:13 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:15:13 [root] INFO: The price is $299.99
2020-05-09 01:15:13 [root] INFO: status: Sold Out
2020-05-09 01:15:16 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:15:16 [root] INFO: The price is $299.99
2020-05-09 01:15:16 [root] INFO: status: Sold Out
2020-05-09 01:15:19 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:15:19 [root] INFO: The price is $399.99
2020-05-09 01:15:19 [root] INFO: status: Sold Out
2020-05-09 01:15:24 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:15:24 [root] INFO: The price is $249.99
2020-05-09 01:15:24 [root] INFO: status: Sold Out
2020-05-09 01:15:28 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:15:28 [root] INFO: The price is $199.99
2020-05-09 01:15:28 [root] INFO: status: Sold Out
2020-05-09 01:15:28 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:15:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573342,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.78565,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 15, 28, 662094),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 15, 5, 876444)}
2020-05-09 01:15:28 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:15:51 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:15:51 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:15:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:15:51 [scrapy.extensions.telnet] INFO: Telnet Password: fddfbeaede4e7766
2020-05-09 01:15:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:15:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:15:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:15:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:15:57 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:15:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:15:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:16:05 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:16:05 [root] INFO: The price is $199.99
2020-05-09 01:16:05 [root] INFO: status: Sold Out
2020-05-09 01:16:07 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:16:07 [root] INFO: The price is $399.99
2020-05-09 01:16:07 [root] INFO: status: Sold Out
2020-05-09 01:16:10 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:16:10 [root] INFO: The price is $249.99
2020-05-09 01:16:10 [root] INFO: status: Sold Out
2020-05-09 01:16:12 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:16:12 [root] INFO: The price is $299.99
2020-05-09 01:16:12 [root] INFO: status: Sold Out
2020-05-09 01:16:15 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:16:15 [root] INFO: The price is $299.99
2020-05-09 01:16:15 [root] INFO: status: Sold Out
2020-05-09 01:16:15 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:16:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573334,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.418333,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 16, 15, 198792),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 15, 57, 780459)}
2020-05-09 01:16:15 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:16:38 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:16:38 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:16:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:16:38 [scrapy.extensions.telnet] INFO: Telnet Password: 7b26ac7d81e351da
2020-05-09 01:16:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:16:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:16:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:16:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:16:44 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:16:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:16:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:16:53 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:16:53 [root] INFO: The price is $299.99
2020-05-09 01:16:53 [root] INFO: status: Sold Out
2020-05-09 01:16:56 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:16:56 [root] INFO: The price is $299.99
2020-05-09 01:16:56 [root] INFO: status: Sold Out
2020-05-09 01:16:59 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:16:59 [root] INFO: The price is $249.99
2020-05-09 01:16:59 [root] INFO: status: Sold Out
2020-05-09 01:17:02 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:17:02 [root] INFO: The price is $399.99
2020-05-09 01:17:02 [root] INFO: status: Sold Out
2020-05-09 01:17:05 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:17:05 [root] INFO: The price is $199.99
2020-05-09 01:17:05 [root] INFO: status: Sold Out
2020-05-09 01:17:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:17:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573358,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.315757,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 17, 5, 588055),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 16, 44, 272298)}
2020-05-09 01:17:05 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:17:28 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:17:28 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:17:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:17:28 [scrapy.extensions.telnet] INFO: Telnet Password: 74df206ad3951a0f
2020-05-09 01:17:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:17:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:17:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:17:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:17:34 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:17:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:17:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:17:43 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:17:43 [root] INFO: The price is $399.99
2020-05-09 01:17:43 [root] INFO: status: Sold Out
2020-05-09 01:17:46 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:17:46 [root] INFO: The price is $299.99
2020-05-09 01:17:46 [root] INFO: status: Sold Out
2020-05-09 01:17:49 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:17:49 [root] INFO: The price is $249.99
2020-05-09 01:17:49 [root] INFO: status: Sold Out
2020-05-09 01:17:51 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:17:51 [root] INFO: The price is $199.99
2020-05-09 01:17:51 [root] INFO: status: Sold Out
2020-05-09 01:17:54 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:17:54 [root] INFO: The price is $299.99
2020-05-09 01:17:54 [root] INFO: status: Sold Out
2020-05-09 01:17:54 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:17:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573350,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.434871,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 17, 54, 114102),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 17, 34, 679231)}
2020-05-09 01:17:54 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:18:17 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:18:17 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:18:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:18:17 [scrapy.extensions.telnet] INFO: Telnet Password: 1f48af9fdd60022e
2020-05-09 01:18:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:18:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:18:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:18:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:18:23 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:18:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:18:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:18:29 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:18:29 [root] INFO: The price is $199.99
2020-05-09 01:18:29 [root] INFO: status: Sold Out
2020-05-09 01:18:32 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:18:32 [root] INFO: The price is $299.99
2020-05-09 01:18:32 [root] INFO: status: Sold Out
2020-05-09 01:18:34 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:18:34 [root] INFO: The price is $299.99
2020-05-09 01:18:34 [root] INFO: status: Sold Out
2020-05-09 01:18:37 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:18:37 [root] INFO: The price is $249.99
2020-05-09 01:18:37 [root] INFO: status: Sold Out
2020-05-09 01:18:39 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:18:39 [root] INFO: The price is $399.99
2020-05-09 01:18:39 [root] INFO: status: Sold Out
2020-05-09 01:18:39 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:18:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573343,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.625829,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 18, 39, 823081),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 18, 23, 197252)}
2020-05-09 01:18:39 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:19:03 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:19:03 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:19:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:19:03 [scrapy.extensions.telnet] INFO: Telnet Password: 23bfb90c34e9455b
2020-05-09 01:19:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:19:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:19:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:19:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:19:08 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:19:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:19:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:19:20 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:19:20 [root] INFO: The price is $249.99
2020-05-09 01:19:20 [root] INFO: status: Sold Out
2020-05-09 01:19:24 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:19:24 [root] INFO: The price is $199.99
2020-05-09 01:19:24 [root] INFO: status: Sold Out
2020-05-09 01:19:26 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:19:26 [root] INFO: The price is $299.99
2020-05-09 01:19:26 [root] INFO: status: Sold Out
2020-05-09 01:19:28 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:19:28 [root] INFO: The price is $299.99
2020-05-09 01:19:28 [root] INFO: status: Sold Out
2020-05-09 01:19:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:19:30 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:19:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573340,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.87321,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 19, 30, 814428),
 'log_count/ERROR': 1,
 'log_count/INFO': 22,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 19, 8, 941218)}
2020-05-09 01:19:30 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:19:56 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:19:56 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:19:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:19:56 [scrapy.extensions.telnet] INFO: Telnet Password: bade84290bd96c75
2020-05-09 01:19:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:20:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:20:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:20:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:20:01 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:20:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:20:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:20:07 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:20:07 [root] INFO: The price is $399.99
2020-05-09 01:20:07 [root] INFO: status: Sold Out
2020-05-09 01:20:12 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:20:12 [root] INFO: The price is $249.99
2020-05-09 01:20:12 [root] INFO: status: Sold Out
2020-05-09 01:20:14 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:20:14 [root] INFO: The price is $299.99
2020-05-09 01:20:14 [root] INFO: status: Sold Out
2020-05-09 01:20:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:20:18 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000129DE820308>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/c4d812c8cf526619bbf4835be1231f36/url
2020-05-09 01:20:20 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000129DFCF3DC8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/c4d812c8cf526619bbf4835be1231f36/url
2020-05-09 01:20:22 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000129DFCF3B48>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/c4d812c8cf526619bbf4835be1231f36/url
2020-05-09 01:20:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000129DE8B7B88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52610): Max retries exceeded with url: /session/c4d812c8cf526619bbf4835be1231f36/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000129DE8B7B88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:20:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:20:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573350,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.652447,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 20, 24, 635476),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 20, 1, 983029)}
2020-05-09 01:20:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:20:49 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:20:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:20:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:20:49 [scrapy.extensions.telnet] INFO: Telnet Password: 8b6d3f2ed141b4a3
2020-05-09 01:20:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:20:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:20:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:20:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:20:55 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:20:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:20:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:21:01 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:21:01 [root] INFO: The price is $199.99
2020-05-09 01:21:01 [root] INFO: status: Sold Out
2020-05-09 01:21:05 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:21:05 [root] INFO: The price is $249.99
2020-05-09 01:21:05 [root] INFO: status: Sold Out
2020-05-09 01:21:07 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:21:07 [root] INFO: The price is $399.99
2020-05-09 01:21:07 [root] INFO: status: Sold Out
2020-05-09 01:21:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:21:11 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CB4F971208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/c7876ae660d07cee6a65297db22b22ce/url
2020-05-09 01:21:13 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CB50E32F08>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/c7876ae660d07cee6a65297db22b22ce/url
2020-05-09 01:21:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CB50E33388>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/c7876ae660d07cee6a65297db22b22ce/url
2020-05-09 01:21:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001CB50E336C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52762): Max retries exceeded with url: /session/c7876ae660d07cee6a65297db22b22ce/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CB50E336C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:21:17 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:21:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573356,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 22.133662,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 21, 17, 881306),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 20, 55, 747644)}
2020-05-09 01:21:17 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:21:43 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:21:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:21:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:21:43 [scrapy.extensions.telnet] INFO: Telnet Password: 0dcea05220ab8f2d
2020-05-09 01:21:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:21:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:21:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:21:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:21:49 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:21:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:21:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:21:57 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:21:57 [root] INFO: The price is $199.99
2020-05-09 01:21:57 [root] INFO: status: Sold Out
2020-05-09 01:22:00 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:22:00 [root] INFO: The price is $299.99
2020-05-09 01:22:00 [root] INFO: status: Sold Out
2020-05-09 01:22:03 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:22:03 [root] INFO: The price is $249.99
2020-05-09 01:22:03 [root] INFO: status: Sold Out
2020-05-09 01:22:05 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:22:05 [root] INFO: The price is $299.99
2020-05-09 01:22:05 [root] INFO: status: Sold Out
2020-05-09 01:22:07 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:22:07 [root] INFO: The price is $399.99
2020-05-09 01:22:07 [root] INFO: status: Sold Out
2020-05-09 01:22:07 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:22:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573345,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.130444,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 22, 7, 64686),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 21, 49, 934242)}
2020-05-09 01:22:07 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:22:30 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:22:30 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:22:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:22:30 [scrapy.extensions.telnet] INFO: Telnet Password: cbb9c6b4f753e72a
2020-05-09 01:22:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:22:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:22:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:22:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:22:36 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:22:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:22:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:22:43 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:22:43 [root] INFO: The price is $299.99
2020-05-09 01:22:43 [root] INFO: status: Sold Out
2020-05-09 01:22:47 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:22:47 [root] INFO: The price is $199.99
2020-05-09 01:22:47 [root] INFO: status: Sold Out
2020-05-09 01:22:50 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:22:50 [root] INFO: The price is $399.99
2020-05-09 01:22:50 [root] INFO: status: Sold Out
2020-05-09 01:22:52 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:22:52 [root] INFO: The price is $299.99
2020-05-09 01:22:52 [root] INFO: status: Sold Out
2020-05-09 01:22:55 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:22:55 [root] INFO: The price is $249.99
2020-05-09 01:22:55 [root] INFO: status: Sold Out
2020-05-09 01:22:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:22:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573367,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 18.544219,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 22, 55, 200888),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 22, 36, 656669)}
2020-05-09 01:22:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:23:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:23:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:23:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:23:18 [scrapy.extensions.telnet] INFO: Telnet Password: 57ffb9053f2855bd
2020-05-09 01:23:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:23:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:23:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:23:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:23:24 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:23:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:23:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:23:33 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:23:33 [root] INFO: The price is $249.99
2020-05-09 01:23:33 [root] INFO: status: Sold Out
2020-05-09 01:23:37 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:23:37 [root] INFO: The price is $299.99
2020-05-09 01:23:37 [root] INFO: status: Sold Out
2020-05-09 01:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 01:23:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013883B47608>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f8d4b7fc8be8019f0013f67afc7f461b/url
2020-05-09 01:23:43 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013885024788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f8d4b7fc8be8019f0013f67afc7f461b/url
2020-05-09 01:23:45 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013885024C08>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f8d4b7fc8be8019f0013f67afc7f461b/url
2020-05-09 01:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000013885024548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=53162): Max retries exceeded with url: /session/f8d4b7fc8be8019f0013f67afc7f461b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013885024548>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:23:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013883D90788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f8d4b7fc8be8019f0013f67afc7f461b/url
2020-05-09 01:23:51 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013885021308>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f8d4b7fc8be8019f0013f67afc7f461b/url
2020-05-09 01:23:53 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000138850212C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/f8d4b7fc8be8019f0013f67afc7f461b/url
2020-05-09 01:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000013883DAB888>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=53162): Max retries exceeded with url: /session/f8d4b7fc8be8019f0013f67afc7f461b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000013883DAB888>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 01:23:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:23:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573420,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 30.908628,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 23, 55, 269124),
 'log_count/ERROR': 3,
 'log_count/INFO': 16,
 'log_count/WARNING': 6,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 2,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 6, 23, 24, 360496)}
2020-05-09 01:23:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 01:24:21 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 01:24:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 01:24:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 01:24:21 [scrapy.extensions.telnet] INFO: Telnet Password: e6e3e324834f375b
2020-05-09 01:24:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 01:24:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 01:24:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 01:24:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 01:24:27 [scrapy.core.engine] INFO: Spider opened
2020-05-09 01:24:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 01:24:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 01:24:34 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 01:24:34 [root] INFO: The price is $249.99
2020-05-09 01:24:34 [root] INFO: status: Sold Out
2020-05-09 01:24:36 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 01:24:36 [root] INFO: The price is $399.99
2020-05-09 01:24:36 [root] INFO: status: Sold Out
2020-05-09 01:24:39 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 01:24:39 [root] INFO: The price is $299.99
2020-05-09 01:24:39 [root] INFO: status: Sold Out
2020-05-09 01:24:41 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 01:24:41 [root] INFO: The price is $299.99
2020-05-09 01:24:41 [root] INFO: status: Sold Out
2020-05-09 01:24:43 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 01:24:43 [root] INFO: The price is $199.99
2020-05-09 01:24:43 [root] INFO: status: Sold Out
2020-05-09 01:24:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 01:24:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573428,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.755295,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 6, 24, 43, 847162),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 6, 24, 27, 91867)}
2020-05-09 01:24:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 08:00:36 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 08:00:36 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 08:00:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 08:00:36 [scrapy.extensions.telnet] INFO: Telnet Password: b0b99e5ba8838d50
2020-05-09 08:00:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 08:00:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 08:00:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 08:00:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 08:00:42 [scrapy.core.engine] INFO: Spider opened
2020-05-09 08:00:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 08:00:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 08:00:49 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 08:00:49 [root] INFO: The price is $299.99
2020-05-09 08:00:49 [root] INFO: status: Sold Out
2020-05-09 08:00:52 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 08:00:52 [root] INFO: The price is $399.99
2020-05-09 08:00:52 [root] INFO: status: Sold Out
2020-05-09 08:00:55 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 08:00:55 [root] INFO: The price is $249.99
2020-05-09 08:00:55 [root] INFO: status: Sold Out
2020-05-09 08:00:57 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 08:00:57 [root] INFO: The price is $199.99
2020-05-09 08:00:57 [root] INFO: status: Add to Cart
2020-05-09 08:00:59 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 08:00:59 [root] INFO: The price is $299.99
2020-05-09 08:00:59 [root] INFO: status: Sold Out
2020-05-09 08:00:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 08:00:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573489,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.007492,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 13, 0, 59, 915121),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 13, 0, 42, 907629)}
2020-05-09 08:00:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 08:01:23 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 08:01:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 08:01:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 08:01:23 [scrapy.extensions.telnet] INFO: Telnet Password: f103b45860e3ce22
2020-05-09 08:01:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 08:01:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 08:01:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 08:01:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 08:01:29 [scrapy.core.engine] INFO: Spider opened
2020-05-09 08:01:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 08:01:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 08:01:35 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 08:01:35 [root] INFO: The price is $199.99
2020-05-09 08:01:35 [root] INFO: status: Add to Cart
2020-05-09 08:01:39 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 08:01:39 [root] INFO: The price is $299.99
2020-05-09 08:01:39 [root] INFO: status: Sold Out
2020-05-09 08:01:41 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 08:01:41 [root] INFO: The price is $299.99
2020-05-09 08:01:41 [root] INFO: status: Sold Out
2020-05-09 08:01:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 08:01:46 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002D55301B648>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/65b1dd38422eb263a085993aec3173cb/url
2020-05-09 08:01:48 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002D5519E9608>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/65b1dd38422eb263a085993aec3173cb/url
2020-05-09 08:01:50 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002D5519E9748>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/65b1dd38422eb263a085993aec3173cb/url
2020-05-09 08:01:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002D5519ED788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 33, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=53652): Max retries exceeded with url: /session/65b1dd38422eb263a085993aec3173cb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002D5519ED788>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 08:01:52 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 08:01:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573484,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 23.117557,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 13, 1, 52, 376349),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 13, 1, 29, 258792)}
2020-05-09 08:01:52 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 08:02:17 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 08:02:17 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 08:02:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 08:02:17 [scrapy.extensions.telnet] INFO: Telnet Password: 32deaab9985ed673
2020-05-09 08:02:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 08:02:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 08:02:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 08:02:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 08:02:23 [scrapy.core.engine] INFO: Spider opened
2020-05-09 08:02:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 08:02:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 08:02:32 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 08:02:32 [root] INFO: The price is $299.99
2020-05-09 08:02:32 [root] INFO: status: Sold Out
2020-05-09 08:02:36 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 08:02:36 [root] INFO: The price is $199.99
2020-05-09 08:02:36 [root] INFO: status: Add to Cart
2020-05-09 08:02:39 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 08:02:39 [root] INFO: The price is $399.99
2020-05-09 08:02:39 [root] INFO: status: Sold Out
2020-05-09 08:02:42 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 08:02:42 [root] INFO: The price is $249.99
2020-05-09 08:02:42 [root] INFO: status: Sold Out
2020-05-09 08:02:44 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 08:02:44 [root] INFO: The price is $299.99
2020-05-09 08:02:44 [root] INFO: status: Sold Out
2020-05-09 08:02:44 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 08:02:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 572966,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.368658,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 13, 2, 44, 197798),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 13, 2, 23, 829140)}
2020-05-09 08:02:44 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 08:03:07 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 08:03:07 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 08:03:07 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 08:03:07 [scrapy.extensions.telnet] INFO: Telnet Password: 95fed9a4b2be4bca
2020-05-09 08:03:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 08:03:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 08:03:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 08:03:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 08:03:13 [scrapy.core.engine] INFO: Spider opened
2020-05-09 08:03:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 08:03:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 08:03:23 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 08:03:23 [root] INFO: The price is $399.99
2020-05-09 08:03:23 [root] INFO: status: Sold Out
2020-05-09 08:03:30 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 08:03:30 [root] INFO: The price is $249.99
2020-05-09 08:03:30 [root] INFO: status: Sold Out
2020-05-09 08:03:33 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 08:03:33 [root] INFO: The price is $299.99
2020-05-09 08:03:33 [root] INFO: status: Sold Out
2020-05-09 08:03:39 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 08:03:39 [root] INFO: The price is $199.99
2020-05-09 08:03:39 [root] INFO: status: Add to Cart
2020-05-09 08:03:42 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 08:03:42 [root] INFO: The price is $299.99
2020-05-09 08:03:42 [root] INFO: status: Sold Out
2020-05-09 08:03:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 08:03:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 572968,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 29.231008,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 13, 3, 42, 764365),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 13, 3, 13, 533357)}
2020-05-09 08:03:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:32:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:32:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:32:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:32:10 [scrapy.extensions.telnet] INFO: Telnet Password: 16c08f9ca62b0cc2
2020-05-09 10:32:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:32:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:32:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:32:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:32:15 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:32:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:32:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:32:24 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:32:24 [root] INFO: The price is $299.99
2020-05-09 10:32:24 [root] INFO: status: Sold Out
2020-05-09 10:32:28 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:32:28 [root] INFO: The price is $299.99
2020-05-09 10:32:28 [root] INFO: status: Sold Out
2020-05-09 10:32:30 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:32:30 [root] INFO: The price is $399.99
2020-05-09 10:32:30 [root] INFO: status: Sold Out
2020-05-09 10:32:33 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:32:33 [root] INFO: The price is $249.99
2020-05-09 10:32:33 [root] INFO: status: Add to Cart
2020-05-09 10:32:35 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:32:35 [root] INFO: The price is $199.99
2020-05-09 10:32:35 [root] INFO: status: Sold Out
2020-05-09 10:32:35 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:32:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573940,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.026414,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 32, 35, 936815),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 15, 32, 15, 910401)}
2020-05-09 10:32:35 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:34:51 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:34:51 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:34:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:34:51 [scrapy.extensions.telnet] INFO: Telnet Password: b351c72b449601bb
2020-05-09 10:34:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:34:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:34:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:34:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:34:57 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:34:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:34:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:35:02 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:35:02 [root] INFO: The price is $399.99
2020-05-09 10:35:02 [root] INFO: status: Sold Out
2020-05-09 10:35:05 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:35:05 [root] INFO: The price is $299.99
2020-05-09 10:35:05 [root] INFO: status: Sold Out
2020-05-09 10:35:07 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:35:07 [root] INFO: The price is $299.99
2020-05-09 10:35:07 [root] INFO: status: Sold Out
2020-05-09 10:35:09 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:35:09 [root] INFO: The price is $249.99
2020-05-09 10:35:09 [root] INFO: status: Add to Cart
2020-05-09 10:35:10 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:35:10 [root] INFO: The price is $199.99
2020-05-09 10:35:10 [root] INFO: status: Sold Out
2020-05-09 10:35:10 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:35:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573940,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 13.56309,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 35, 10, 980069),
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2020, 5, 9, 15, 34, 57, 416979)}
2020-05-09 10:35:10 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:35:29 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:35:29 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:35:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:35:29 [scrapy.extensions.telnet] INFO: Telnet Password: 8f203f68142da9b1
2020-05-09 10:35:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:35:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:35:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:35:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:35:35 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:35:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:35:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:35:41 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:35:41 [root] INFO: The price is $199.99
2020-05-09 10:35:41 [root] INFO: status: Sold Out
2020-05-09 10:35:46 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:35:46 [root] INFO: The price is $249.99
2020-05-09 10:35:46 [root] INFO: status: Add to Cart
2020-05-09 10:35:49 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:35:49 [root] INFO: The price is $399.99
2020-05-09 10:35:49 [root] INFO: status: Sold Out
2020-05-09 10:35:51 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:35:51 [root] INFO: The price is $299.99
2020-05-09 10:35:51 [root] INFO: status: Sold Out
2020-05-09 10:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 34, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 10:35:54 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:35:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 575088,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.346281,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 35, 54, 681625),
 'log_count/ERROR': 1,
 'log_count/INFO': 22,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 15, 35, 35, 335344)}
2020-05-09 10:35:54 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:38:24 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:38:24 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:38:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:38:24 [scrapy.extensions.telnet] INFO: Telnet Password: a5a39d3fc8aae9c3
2020-05-09 10:38:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:38:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:38:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:38:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:38:30 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:38:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:38:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:38:37 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:38:37 [root] INFO: The price is $299.99
2020-05-09 10:38:37 [root] INFO: status: Sold Out
2020-05-09 10:38:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:38:41 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:38:41 [root] INFO: The price is $249.99
2020-05-09 10:38:41 [root] INFO: status: Add to Cart
2020-05-09 10:38:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:38:44 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:38:44 [root] INFO: The price is $199.99
2020-05-09 10:38:44 [root] INFO: status: Sold Out
2020-05-09 10:38:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:38:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 34, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 10:38:48 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D5BE2A43C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/158426d03e540c4b99ed53fe17c43577/url
2020-05-09 10:38:50 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D5BE3EA148>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/158426d03e540c4b99ed53fe17c43577/url
2020-05-09 10:38:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D5BE3EA248>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/158426d03e540c4b99ed53fe17c43577/url
2020-05-09 10:38:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D5BE3EA848>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 34, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55987): Max retries exceeded with url: /session/158426d03e540c4b99ed53fe17c43577/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D5BE3EA848>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 10:38:54 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:38:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 574065,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 24.264895,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 38, 54, 536430),
 'log_count/ERROR': 5,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'spider_exceptions/TypeError': 3,
 'start_time': datetime.datetime(2020, 5, 9, 15, 38, 30, 271535)}
2020-05-09 10:38:54 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:39:44 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:39:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:39:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:39:44 [scrapy.extensions.telnet] INFO: Telnet Password: eb7c9ffee4334792
2020-05-09 10:39:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:39:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:39:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:39:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:39:50 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:39:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:39:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:39:57 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:39:57 [root] INFO: The price is $249.99
2020-05-09 10:39:57 [root] INFO: status: Add to Cart
2020-05-09 10:39:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:40:01 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:40:01 [root] INFO: The price is $199.99
2020-05-09 10:40:01 [root] INFO: status: Sold Out
2020-05-09 10:40:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:40:03 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:40:03 [root] INFO: The price is $299.99
2020-05-09 10:40:03 [root] INFO: status: Sold Out
2020-05-09 10:40:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:40:05 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:40:05 [root] INFO: The price is $299.99
2020-05-09 10:40:05 [root] INFO: status: Sold Out
2020-05-09 10:40:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:40:07 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:40:07 [root] INFO: The price is $399.99
2020-05-09 10:40:07 [root] INFO: status: Sold Out
2020-05-09 10:40:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:40:07 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:40:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573467,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 17.486194,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 40, 7, 926404),
 'log_count/ERROR': 5,
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/TypeError': 5,
 'start_time': datetime.datetime(2020, 5, 9, 15, 39, 50, 440210)}
2020-05-09 10:40:07 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:41:19 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:41:19 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:41:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:41:19 [scrapy.extensions.telnet] INFO: Telnet Password: dded0bdf7987ab4b
2020-05-09 10:41:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:41:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:41:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:41:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:41:25 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:41:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:41:33 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:41:33 [root] INFO: The price is $249.99
2020-05-09 10:41:33 [root] INFO: status: Add to Cart
2020-05-09 10:41:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:41:36 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:41:36 [root] INFO: The price is $199.99
2020-05-09 10:41:36 [root] INFO: status: Sold Out
2020-05-09 10:41:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:41:38 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:41:38 [root] INFO: The price is $299.99
2020-05-09 10:41:38 [root] INFO: status: Sold Out
2020-05-09 10:41:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:41:41 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:41:41 [root] INFO: The price is $299.99
2020-05-09 10:41:41 [root] INFO: status: Sold Out
2020-05-09 10:41:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:41:44 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:41:44 [root] INFO: The price is $399.99
2020-05-09 10:41:44 [root] INFO: status: Sold Out
2020-05-09 10:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 52, in parse
    file.write('Name is: %s \n', name)
TypeError: write() takes exactly one argument (2 given)
2020-05-09 10:41:44 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:41:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573953,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 19.83298,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 41, 44, 929322),
 'log_count/ERROR': 5,
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/TypeError': 5,
 'start_time': datetime.datetime(2020, 5, 9, 15, 41, 25, 96342)}
2020-05-09 10:41:44 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:47:12 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:47:12 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:47:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:47:12 [scrapy.extensions.telnet] INFO: Telnet Password: 3818a72e1e66c72a
2020-05-09 10:47:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:47:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:47:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:47:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:47:17 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:47:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:47:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:47:23 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:47:23 [root] INFO: The price is $299.99
2020-05-09 10:47:23 [root] INFO: status: Sold Out
2020-05-09 10:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: {0} \n'.format(act))
NameError: name 'act' is not defined
2020-05-09 10:47:26 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:47:26 [root] INFO: The price is $199.99
2020-05-09 10:47:26 [root] INFO: status: Sold Out
2020-05-09 10:47:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: {0} \n'.format(act))
NameError: name 'act' is not defined
2020-05-09 10:47:28 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:47:28 [root] INFO: The price is $299.99
2020-05-09 10:47:28 [root] INFO: status: Sold Out
2020-05-09 10:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: {0} \n'.format(act))
NameError: name 'act' is not defined
2020-05-09 10:47:31 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:47:31 [root] INFO: The price is $249.99
2020-05-09 10:47:31 [root] INFO: status: Add to Cart
2020-05-09 10:47:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: {0} \n'.format(act))
NameError: name 'act' is not defined
2020-05-09 10:47:34 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:47:34 [root] INFO: The price is $399.99
2020-05-09 10:47:34 [root] INFO: status: Sold Out
2020-05-09 10:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: {0} \n'.format(act))
NameError: name 'act' is not defined
2020-05-09 10:47:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:47:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573976,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 16.691144,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 47, 34, 541643),
 'log_count/ERROR': 5,
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/NameError': 5,
 'start_time': datetime.datetime(2020, 5, 9, 15, 47, 17, 850499)}
2020-05-09 10:47:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:52:14 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:52:14 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:52:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:52:14 [scrapy.extensions.telnet] INFO: Telnet Password: 07a2d8c14e572dfc
2020-05-09 10:52:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:52:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:52:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:52:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:52:20 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:52:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:52:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:52:27 [root] INFO: Name is: Nintendo - Switch 32GB Console - Gray Joy-Con
2020-05-09 10:52:27 [root] INFO: The price is $299.99
2020-05-09 10:52:27 [root] INFO: status: Sold Out
2020-05-09 10:52:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: '+act+'\n')
NameError: name 'act' is not defined
2020-05-09 10:52:29 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:52:29 [root] INFO: The price is $299.99
2020-05-09 10:52:29 [root] INFO: status: Sold Out
2020-05-09 10:52:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-neon-red-neon-blue-joy-con/6364255.p?skuId=6364255> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: '+act+'\n')
NameError: name 'act' is not defined
2020-05-09 10:52:32 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:52:32 [root] INFO: The price is $399.99
2020-05-09 10:52:32 [root] INFO: status: Sold Out
2020-05-09 10:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/logitech-g920-driving-force-racing-wheel-for-xbox-one-and-windows-black/4223402.p?skuId=4223402> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: '+act+'\n')
NameError: name 'act' is not defined
2020-05-09 10:52:37 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:52:37 [root] INFO: The price is $249.99
2020-05-09 10:52:37 [root] INFO: status: Add to Cart
2020-05-09 10:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/apple-ipad-latest-model-with-wi-fi-32gb-silver/5985610.p?skuId=5985610> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: '+act+'\n')
NameError: name 'act' is not defined
2020-05-09 10:52:40 [root] INFO: Name is: Nintendo - Switch 32GB Lite - Turquoise
2020-05-09 10:52:40 [root] INFO: The price is $199.99
2020-05-09 10:52:40 [root] INFO: status: Add to Cart
2020-05-09 10:52:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 58, in parse
    file.write('status: '+act+'\n')
NameError: name 'act' is not defined
2020-05-09 10:52:40 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:52:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 574551,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 20.02559,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 52, 40, 663011),
 'log_count/ERROR': 5,
 'log_count/INFO': 25,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/NameError': 5,
 'start_time': datetime.datetime(2020, 5, 9, 15, 52, 20, 637421)}
2020-05-09 10:52:40 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-09 10:54:22 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: MyBot)
2020-05-09 10:54:22 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-09 10:54:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'MyBot',
 'LOG_FILE': 'log/scrapy 2020 5 9.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'MyBot.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['MyBot.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}
2020-05-09 10:54:22 [scrapy.extensions.telnet] INFO: Telnet Password: 909cc6b69c02cf85
2020-05-09 10:54:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-05-09 10:54:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-09 10:54:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-09 10:54:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-09 10:54:28 [scrapy.core.engine] INFO: Spider opened
2020-05-09 10:54:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-09 10:54:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-09 10:54:33 [root] INFO: Name is: Logitech - G920 Driving Force Racing Wheel for Xbox One and Windows - Black
2020-05-09 10:54:33 [root] INFO: The price is $399.99
2020-05-09 10:54:33 [root] INFO: status: Sold Out
2020-05-09 10:54:37 [root] INFO: Name is: Apple - iPad (Latest Model) with Wi-Fi - 32GB - Silver
2020-05-09 10:54:37 [root] INFO: The price is $249.99
2020-05-09 10:54:37 [root] INFO: status: Add to Cart
2020-05-09 10:54:39 [root] INFO: Name is: Nintendo - Switch 32GB Console - Neon Red/Neon Blue Joy-Con
2020-05-09 10:54:39 [root] INFO: The price is $299.99
2020-05-09 10:54:39 [root] INFO: status: Sold Out
2020-05-09 10:54:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-console-gray-joy-con/6364253.p?skuId=6364253> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 34, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\packages\six.py", line 734, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1344, in getresponse
    response.begin()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 306, in begin
    version, status, reason = self._read_status()
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 267, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\shuwz\anaconda3\lib\socket.py", line 589, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2020-05-09 10:54:43 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B1B8045348>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1b2e2521bc59f3b421875a28f9de274a/url
2020-05-09 10:54:45 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B1B97B1E48>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1b2e2521bc59f3b421875a28f9de274a/url
2020-05-09 10:54:47 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B1B97B90C8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/1b2e2521bc59f3b421875a28f9de274a/url
2020-05-09 10:54:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bestbuy.com/site/nintendo-switch-32gb-lite-turquoise/6257139.p?skuId=6257139> (referer: None)
Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Users\shuwz\anaconda3\lib\http\client.py", line 966, in send
    self.connect()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002B1B97B9748>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shuwz\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\shuwz\Documents\Coding\MyBot\MyBot\spiders\bot_spider.py", line 34, in parse
    self.driver.get(response.url)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\shuwz\AppData\Roaming\Python\Python37\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 80, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\request.py", line 171, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 760, in urlopen
    **response_kw
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "C:\Users\shuwz\anaconda3\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=57003): Max retries exceeded with url: /session/1b2e2521bc59f3b421875a28f9de274a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B1B97B9748>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2020-05-09 10:54:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-09 10:54:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2823,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 573983,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 21.186038,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 9, 15, 54, 49, 697550),
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'log_count/WARNING': 3,
 'response_received_count': 6,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/MaxRetryError': 1,
 'spider_exceptions/ProtocolError': 1,
 'start_time': datetime.datetime(2020, 5, 9, 15, 54, 28, 511512)}
2020-05-09 10:54:49 [scrapy.core.engine] INFO: Spider closed (finished)
